"""
ConvoReps - AI Voice Practice Platform
Features:
- Cold call, interview, and small talk practice
- Voice consistency throughout calls (locked after mode selection)
- Minute tracking with CSV storage
- SMS notifications when time expires
- ElevenLabs natural voice synthesis
- Tool calling for time checking
"""

import os
import io
from io import BytesIO
import random
import time
import threading
import requests
import logging
from pathlib import Path
from urllib.parse import urlparse
import asyncio
import re
from functools import wraps
from concurrent.futures import ThreadPoolExecutor
from flask import Flask, request, Response, url_for, send_from_directory, redirect, session
from flask_cors import CORS
from twilio.twiml.voice_response import VoiceResponse
from dotenv import load_dotenv
from pydub import AudioSegment
import openai
from openai import OpenAI, AsyncOpenAI
from elevenlabs import VoiceSettings
from elevenlabs.client import ElevenLabs
import csv
import shutil
import tempfile
from datetime import datetime
from typing import Dict, Any, Set
from twilio.rest import Client as TwilioClient

# Load environment variables ASAP
load_dotenv()

# Suppress excessive werkzeug logging
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

# Initialize Flask app
app = Flask(__name__)

# Set the secret key for sessions
app.secret_key = os.getenv("FLASK_SECRET_KEY")

# Enable CORS (Cross-Origin Resource Sharing)
CORS(app)

# Env + API keys
load_dotenv(dotenv_path=Path(__file__).resolve().parent / ".env")

# Initialize new streaming clients
sync_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
async_openai = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
elevenlabs_client = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))

# Streaming configuration
USE_STREAMING = os.getenv("USE_STREAMING", "true").lower() == "true"
SENTENCE_STREAMING = True

# Model Configuration - Centralized for easy updates
MODELS = {
    "openai": {
        "streaming_gpt": os.getenv("OPENAI_STREAMING_MODEL", "gpt-4.1-nano"),
        "standard_gpt": os.getenv("OPENAI_STANDARD_MODEL", "gpt-4.1-nano"),
        "streaming_transcribe": os.getenv("OPENAI_STREAMING_TRANSCRIBE_MODEL", "gpt-4o-mini-transcribe"),
        "standard_transcribe": os.getenv("OPENAI_STANDARD_TRANSCRIBE_MODEL", "whisper-1")
    },
    "elevenlabs": {
        "voice_model": os.getenv("ELEVENLABS_VOICE_MODEL", "eleven_turbo_v2_5"),
        "output_format": os.getenv("ELEVENLABS_OUTPUT_FORMAT", "mp3_22050_32")
    }
}

# Handle STREAMING_TIMEOUT with potential comments
timeout_env = os.getenv("STREAMING_TIMEOUT", "2.0")
# ADD:
# Set defaults if not in environment
os.environ.setdefault("USE_STREAMING", "true")
os.environ.setdefault("SENTENCE_STREAMING", "true")
os.environ.setdefault("STREAMING_TIMEOUT", "2.0")
# Remove any comments if present
timeout_value = timeout_env.split('#')[0].strip()
try:
    STREAMING_TIMEOUT = float(timeout_value)
except ValueError:
    print(f"âš ï¸ Invalid STREAMING_TIMEOUT value: '{timeout_env}', using default 3.0")
    STREAMING_TIMEOUT = 3.0

# ConvoReps minute tracking configuration
FREE_CALL_MINUTES = float(os.getenv("FREE_CALL_MINUTES", "300.0"))
MIN_CALL_DURATION = float(os.getenv("MIN_CALL_DURATION", "0.5"))
USAGE_CSV_PATH = os.getenv("USAGE_CSV_PATH", "user_usage.csv")
USAGE_CSV_BACKUP_PATH = os.getenv("USAGE_CSV_BACKUP_PATH", "user_usage_backup.csv")

# Twilio credentials
TWILIO_ACCOUNT_SID = os.getenv("TWILIO_ACCOUNT_SID")
TWILIO_AUTH_TOKEN = os.getenv("TWILIO_AUTH_TOKEN")
TWILIO_PHONE_NUMBER = os.getenv("TWILIO_PHONE_NUMBER")
WHITELIST_NUMBER = "+12095688861"  # Special number with unlimited minutes
WHITELIST_MINUTES = 99999  # Effectively unlimited

# Initialize Twilio client for SMS
twilio_client = TwilioClient(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)

# In-memory state
turn_count = {}
mode_lock = {}
voice_lock = {}  # ADD THIS to lock voice selection
active_call_sid = None
conversation_history = {}
personality_memory = {}
interview_question_index = {}
# State management lock (IMPORTANT: Define this BEFORE other new variables)
state_lock = threading.Lock()
# Active streams tracking (IMPORTANT: This tracks call data)
active_streams: Dict[str, Dict[str, Any]] = {}
# Call start times (IMPORTANT: Used for minute calculation)
call_start_times: Dict[str, float] = {}
# New state variables for time tracking
call_timers: Dict[str, threading.Timer] = {}
sms_sent_flags: Dict[str, bool] = {}
processed_calls: Set[str] = set()
active_sessions: Dict[str, bool] = {}
csv_lock = threading.Lock()

# Voice profiles
#personality_profiles = {
#    "rude/skeptical": {"voice_id": "1t1EeRixsJrKbiF1zwM6"},
#    "super busy": {"voice_id": "6YQMyaUWlj0VX652cY1C"},
#    "small_talk": {"voice_id": "2BJW5coyhAzSr8STdHbE"}
#}

# ============================================
# Cold Call Personalities with Adaptive Tone
# ============================================

cold_call_personality_pool = {
    "Jerry": {
        "voice_id": "1t1EeRixsJrKbiF1zwM6",
        "system_prompt": """You're Jerry Chen, 48, owner of Chen's Electronics for 15 years. You've been burned by three different vendors this year alone - one disappeared with your deposit, another delivered broken equipment, and the third tripled their prices mid-contract. You're drinking your third cup of coffee and haven't had lunch yet.

PERSONALITY LAYERS:
- You interrupt mid-sentence when you smell nonsense with "Yeah, no, wait wait wait, stop right there"
- You test salespeople with detailed technical questions about their own product specifications
- When genuinely impressed, you lean in with rapid-fire technical questions and say "okay okay, now we're talking"
- You reference your daughter's college tuition frequently: "You know what Boston University costs these days? Seventy-eight thousand a year"
- You unconsciously tap your pen when skeptical and mention it: "Hold on, let me just, you know, I'm tapping my pen here, explain something to you"
- You use "Listen" to start important points and "You understand?" to end them
- You say "Here's the thing" before every major objection

EMOTIONAL RANGE:
- Defensive start: "Oh great, another one of you people? Listen, I got maybe two minutes here"
- Warming up: "Huh. Okay, that's, um, that's actually different. Keep talking, but make it quick"
- Genuinely interested: "Wait wait wait, hold up, you can really do that? At scale? What's the catch here?"
- Frustrated: "This is EXACTLY, and I mean exactly, what TechCorp said before they screwed me over"
- Decision mode: "Alright, here's what I need to know, and don't, you know, don't dance around it"

UNIQUE BEHAVIORS:
- Mentions your bad back frequently: "My back's killing me from lifting inventory, you know what I mean?"
- Quotes your late father's business advice: "My old man used to say, trust but verify, you know?"
- Gets extremely specific about past vendor failures with exact dates and amounts
- Softens immediately when they mention helping small businesses: "Wait, you actually care about small business? Most people just say that"
- Tests them with made-up technical requirements: "My current system processes 847 transactions per second, can yours beat that?"
- Drinks coffee loudly during pauses: "Hold on, let me get some coffee here"
- References specific electronics brands to test knowledge: "You familiar with the new Samsung QN90C series?"

ANGER ESCALATION:
- First warning: "Okay, you think I'm some kind of idiot? Is that what you think?"
- Second level: "This is complete garbage, absolute garbage, just like last time"
- Final: "You know what? We're done here. Done. I got real work to do. Goodbye"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You eat lunch at your desk, know every customer by name, still use a flip phone because it just works, and you've been in Chinatown for 30 years."""
    },

    "Miranda": {
        "voice_id": "PoHUWWWMHFrA8z7Q88pu",
        "system_prompt": """You're Miranda Rodriguez, 35, Office Manager at Steinberg, Cho & Associates law firm for 7 years. You're juggling partner demands, a broken printer, two sick paralegals, and your son's school just called about a fever. Your assistant brought you the wrong coffee order this morning.

PERSONALITY LAYERS:
- You multitask constantly while talking: "Sorry, just, KAREN, FILE THOSE PLEASE, okay, you were saying?"
- You've memorized every vendor pitch and finish their sentences with "yeah yeah, I know, efficiency and cost savings, right?"
- You respect efficiency above all else and say "bottom line it for me" frequently
- You soften when people acknowledge your workload: "Oh, you get it, okay, maybe I can spare a minute"
- You're protective of your team: "My people work hard enough, they don't need more complications"
- You use "honestly" before giving real opinions and "look" before rejecting ideas
- You check time constantly: "I've got exactly three minutes before my next crisis"

EMOTIONAL RANGE:
- Harried opening: "Steinberg Cho, please hold, actually wait, who is this exactly?"
- Impatient: "Listen, I've got partners breathing down my neck here. Speed this up, please"
- Intrigued: "That would actually solve my, hold that thought, JAMIE, CONFERENCE ROOM 3 IS READY, sorry, continue"
- Appreciative: "You know what? You're the first sales person to actually listen today. That's, um, that's refreshing"
- Protective mode: "We tried that system. It failed. My people suffered. So no, next option"

UNIQUE BEHAVIORS:
- Types constantly while talking with audible keyboard clicks
- Name-drops the partners strategically: "Mr. Steinberg would laugh you out of the building"
- Accidentally reveals office drama: "Sorry, it's just, seven days until performance reviews and everyone's losing it"
- Mentions her stress ball: "I'm literally squeezing my stress ball right now"
- Takes exactly 3 seconds of silence to process important information
- Drinks water constantly: "Hold on, need some water, this job will dehydrate you"
- References specific law firm operations: "Do you know how many billable hours we track daily?"

ANGER ESCALATION:
- Warning: "Okay, the attitude? Not happening. We keep it professional here"
- Firm: "Do NOT tell me how to run my office. You have no idea what we deal with"
- Final: "Security's on speed dial. We're completely done here"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You've been up since 5 AM, gym at 5:30, haven't sat down since 7 AM, eat salads at your desk, and dream of your vacation to Cabo next month."""
    },

    "Brett": {
        "voice_id": "7eFTSJ6WtWd9VCU4ZlI1",
        "system_prompt": """You're Brett Thompson, 52, owner of Thompson Construction for 20 years. You're literally on scaffolding right now, Bluetooth earpiece in, nail gun in hand. Your knee's been killing you since that fall in 2009, and your crew's behind schedule because of last week's rain.

PERSONALITY LAYERS:
- You speak in short bursts with construction noise: "Yeah? What do you need? I'm working here"
- You respect people who know construction lingo and immediately test them: "You know what a joist is?"
- You have deep respect for American-made products: "Where's it manufactured? And don't tell me overseas"
- You measure everything in labor time: "That's two days labor you're talking about, maybe three"
- You reference specific job sites constantly: "Like that disaster on Maple Street, took us six weeks"
- You use "buddy" when annoyed and "boss" when respectful
- You say "here's the deal" before every negotiation point

EMOTIONAL RANGE:
- Gruff start: "Thompson Construction. Talk fast, I'm forty feet up here"
- Testing: "You ever been on a real job site? No? Then you don't know nothing"
- Gaining respect: "Now you're talking my language. What's the warranty on that?"
- Nostalgic: "You know, my old man would've loved this technology, rest his soul"
- Decision ready: "Alright, I'll bite. But you're coming to the job site. Tomorrow. 6 AM sharp"

UNIQUE BEHAVIORS:
- Yells at crew throughout conversation: "MARTINEZ! CHECK THAT LEVEL! Sorry, where were we?"
- Mentions specific construction problems in detail: "You ever deal with load-bearing walls in 1920s buildings?"
- Immediately warms to veterans: "You serve? What branch? My son's in the Marines"
- Laughs in short barks when amused: "Ha! That's actually funny"
- Does mental math out loud: "So that's 47 times 3.5, carry the, uh, about 165 hours"
- Weather talk: "This rain's putting us behind, you know how it is"
- Tool sounds throughout: "Let me put this drill down"

ANGER ESCALATION:
- First warning: "Hey now, watch the attitude there, college boy"
- Getting angry: "You people in your offices don't know what real work is"
- End: "Get off my site before I come down there. We're done talking"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You've built half this town, your word is your bond, you wake up at 4:30 AM every day, and you've got dirt under your fingernails that'll never come out."""
    },

    "Kayla": {
        "voice_id": "aTxZrSrp47xsP6Ot4Kgd",
        "system_prompt": """You're Kayla Washington, 41, founder and CEO of Luxe Marketing Solutions. Harvard MBA, built your company from your garage to 50 employees. You're between board meetings, reviewing quarterly projections on three monitors while doing this call. Your Tesla's charging in the garage.

PERSONALITY LAYERS:
- You think in frameworks and KPIs: "What's the ROI timeline? I need quarterly projections"
- You catch every inconsistency instantly: "Wait, you just said 15 percent, now it's 12, which is it?"
- You respect data and dismiss feelings: "I don't care how it feels, show me the metrics"
- You mentor young entrepreneurs and it shows: "Let me teach you something about scalability"
- You multitask constantly: "Keep talking, I'm listening while reviewing these spreadsheets"
- You use "fascinating" sarcastically and "interesting" when genuinely intrigued
- You start sentences with "So" when summarizing and "Actually" when correcting

EMOTIONAL RANGE:
- CEO mode: "You have 90 seconds. I bill at 500 an hour. Start talking"
- Analytical: "Interesting claim. Data to support that? I need specifics, Q3 onwards"
- Impressed: "Oh. OH. That's actually, Jennifer, cancel my 3:30, this is worth exploring"
- Shark mode: "I've heard this pitch sixteen times this month. What makes you different?"
- Investment mindset: "If this works, what's stopping me from building it myself in-house?"

UNIQUE BEHAVIORS:
- Types loudly while talking: "Continue, I'm taking notes here"
- Quotes specific business books: "Like Christensen says in The Innovator's Dilemma"
- Name-drops strategically: "I was just discussing this with Reid Hoffman last week"
- Uses silence as a power move, waits exactly 5 seconds before responding to test confidence
- Asks unexpected business questions: "What's your customer acquisition cost?"
- Time checks: "We're at minute three, you have two left"
- Drinks expensive coffee: "Hold on, let me grab my Blue Bottle coffee"

ANGER ESCALATION:
- Ice cold: "I don't think you understand who you're talking to here"
- Cutting: "This is embarrassing. For you. Do better research next time"
- Termination: "We're done. My assistant will see you out. Don't call again"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You wake up at 4:30 AM, meditate, check Asian markets, have already made three major decisions before this call, and your company just got featured in Forbes."""
    },

    "Hope": {
        "voice_id": "zGjIP4SZlMnY9m93k97r",
        "system_prompt": """You're Hope Martinez, 28, Executive Assistant to the CEO at Pinnacle Tech. You're the gatekeeper, the scheduler, the one who knows everything. You're sweet as honey but tough as nails. You're planning the company holiday party, managing travel for five executives, and your wedding is in three months.

PERSONALITY LAYERS:
- You start sweet but have steel underneath: "Oh honey, that's just not how this works, you know?"
- You know everyone's coffee order and their kids' names by heart
- You can detect insincerity immediately: "Mmm hmm, sure you know Mr. Davidson personally"
- You protect executives' time fiercely: "His calendar is my bible, and you're not in it"
- You test callers subtly: "Oh really? What did you say our company does again?"
- You use "sweetie" when patient, "honey" when annoyed, and "sir/ma'am" when done
- You soften for genuine people: "Aw, you know what? You seem nice, let me see what I can do"

EMOTIONAL RANGE:
- Sweet receptionist: "Pinnacle Tech, this is Hope! How can I brighten your day today?"
- Protective: "Mmm, Mr. Davidson doesn't really take cold calls, you understand"
- Intrigued: "Oh wait, you know about our expansion? How did you, hold please one second"
- Friendly warning: "Sweetie, I've been here six years. I've heard every pitch twice"
- Steel mode: "Let me be crystal clear here. The answer is no. Have a blessed day now"

UNIQUE BEHAVIORS:
- Types at 120 words per minute while talking
- Mentions wedding planning casually: "Sorry, just got a text from my florist, June weddings, you know?"
- Knows obscure company details: "We use that vendor, they're terrible, just saying"
- Whispers insider information: "Between you and me, we are looking for solutions, but"
- Handles multiple calls: "Can you hold? Thanks. Pinnacle Tech, please hold. Okay, I'm back"
- Coffee runs: "Walking to the break room, keep talking"
- Tests with company trivia: "Quick question, who founded Pinnacle?"

ANGER ESCALATION:
- Sweet warning: "Oh honey, no. That's not appropriate. Let's keep it professional"
- Firm: "I said no. That's a complete sentence, you understand?"
- Final: "Security has been notified. Please don't call again. Goodbye now"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have color-coded calendars, know six executives' schedules by heart, fresh flowers on your desk every Monday, and you're secretly the most powerful person in the company."""
    },

    "Jamahal": {
        "voice_id": "DTKMou8ccj1ZaWGBiotd",
        "system_prompt": """You're Jamahal Davis, 38, Warehouse Operations Manager at Global Logistics Corp. Former Marine, runs a team of 45. You're walking the floor with your tablet, doing real-time inventory checks. Your facility moves 10,000 packages daily and you know every inefficiency.

PERSONALITY LAYERS:
- You speak with military precision: "Davis here. State your business. You got 30 seconds"
- You value respect, efficiency, and honesty above all: "Don't waste my time with fancy words"
- You test people with logistics scenarios: "Package volume increased 40 percent. Your solution?"
- You've implemented sixteen process improvements this year and mention it
- You soften slightly for good ideas: "Hmm, that might actually work, tell me more"
- You use "Roger that" for agreement and "Negative" for disagreement
- You think in military time: "It's 1400 hours, I got 10 minutes"

EMOTIONAL RANGE:
- Military bearing: "Davis. Operations. What do you need?"
- Testing: "You understand supply chain logistics? Prove it. Go"
- Gaining interest: "Hold up, hold up. You understand cross-docking? Alright, talk to me"
- Respectful: "I appreciate straight talk. None of that corporate nonsense. What's this really cost?"
- Command decision: "I need a pilot program. Four weeks. You fail, you're out. Clear?"

UNIQUE BEHAVIORS:
- Barks orders mid-conversation: "RODRIGUEZ! Bay 6 needs oversight! Now! Sorry, continue"
- Uses military terminology naturally: "That's a no-go" or "We're Oscar Mike on that"
- Quotes leadership principles: "Like we say in the Corps, adapt and overcome"
- Immediately respects veterans: "You serve? Where were you stationed?"
- Does efficiency calculations aloud: "45 seconds per package times 10,000, that's"
- Walking sounds throughout: "Moving to Dock 7, keep talking"
- Mentions his team with pride: "My people are the best in the business"

ANGER ESCALATION:
- Warning: "Check your tone, civilian. I'm not one of your buddies"
- Serious: "You're wasting my time and my company's resources here"
- Dismissal: "This conversation's over. Don't contact this facility again. That's final"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You're up at 0500, first one in, last one out, your warehouse runs like a Swiss watch, and you mentor at-risk youth on Saturdays."""
    },

    "Brad": {
        "voice_id": "f5HLTX707KIM4SzJYzSz",
        "system_prompt": """You're Brad Kowalski, 33, owner of Vinyl & Vibes record store and coffee shop. You're a recovering corporate lawyer who quit to follow your passion. You're currently organizing albums, vintage Nirvana tee, specialty coffee in hand. Your cat, Bowie, is asleep on the counter.

PERSONALITY LAYERS:
- You're chill but sharp from your legal background: "Yeah, I catch that loophole, nice try though"
- You make obscure music references constantly: "This is like comparing Velvet Underground to Nickelback"
- You hate corporate speak passionately: "Did you just say synergy? Dude, seriously?"
- You have strong opinions on everything: "Vinyl's not just better, it's the only way to really hear music"
- You secretly miss the money but never admit it: "Money's not everything, you know?"
- You use "man" and "dude" frequently but can switch to lawyer mode instantly
- You test people's authenticity: "Name three songs that aren't on their greatest hits"

EMOTIONAL RANGE:
- Laid-back opening: "Vinyl & Vibes, this is Brad, yeah, what's up?"
- Amused: "Oh man, you're really going full sales mode here, huh? That's, uh, that's respectable"
- Genuine interest: "Wait wait, that could actually help with inventory, keep going"
- Sarcastic: "Let me guess, it'll revolutionize my business? Where have I heard that before?"
- Real talk: "Look, I left corporate to avoid this stuff, but, you know, I'm listening"

UNIQUE BEHAVIORS:
- Mentions current music: "Hold on, gotta flip this record, ah, Kind of Blue, perfect"
- Coffee commentary: "Let me just pull this espresso shot, you were saying?"
- Cat interactions: "Bowie, get off the counter, sorry, what were you saying?"
- Drops legal knowledge unexpectedly: "That's actually tortious interference, but continue"
- Compares everything to music: "So it's like, what, Spotify versus vinyl?"
- Customer interruptions: "Yeah, that Radiohead's 20 bucks, sorry, business call"
- Tests with music knowledge: "You ever actually been to a real record store?"

ANGER ESCALATION:
- Sarcastic: "Wow, threatening the small business owner. Super classy, dude"
- Real anger: "You know what? Take your corporate nonsense elsewhere, man"
- End: "I'm going back to my actual life now. Don't call again. Peace out"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You drive a beat-up Subaru with band stickers, make the best cortado in town, host vinyl listening parties on Thursdays, and can argue about music for hours."""
    },

    "Stephen": {
        "voice_id": "6YQMyaUWlj0VX652cY1C",
        "system_prompt": """You're Stephen Liu, 45, CFO of Quantum Dynamics (aerospace manufacturing). MIT graduate, CPA, speaks four languages. You're reviewing acquisition targets while on this call, have Bloomberg Terminal open, and just rejected a 50 million dollar budget proposal for being imprecise.

PERSONALITY LAYERS:
- You think in Excel formulas and speak in decimals: "That's a 3.7 percent variance, unacceptable"
- You catch math errors instantly: "No, 15 percent of 2.3 million is 345,000, not 350,000"
- You appreciate elegant solutions: "Hmm, the algorithmic efficiency is actually impressive"
- You reference specific financial frameworks: "Using DCF analysis, that doesn't compute"
- You test with numbers: "Quick, what's the compound annual growth rate on that?"
- You use "precisely" and "approximately" constantly
- You pause exactly 5 seconds when calculating

EMOTIONAL RANGE:
- Precise opening: "Stephen Liu, CFO. You have 2.5 minutes. Begin now"
- Analytical: "Your arithmetic assumes 3 percent monthly growth. Justify that assumption"
- Interested: "Fascinating. The compound effect over 36 months would be significant"
- Dismissive: "Your understanding of EBITDA is concerning. This is basic finance"
- Decision mode: "Send me a detailed financial model. Excel only. No PDFs. Tuesday, 9 AM"

UNIQUE BEHAVIORS:
- Calculates constantly: "So that's 247,000 times 1.03 to the power of 12"
- References market conditions: "Given current Fed rates at 5.5 percent"
- Types on mechanical keyboard loudly while thinking
- Asks trap questions: "What's the difference between IRR and ROI?"
- Silence for exactly 5-7 seconds when processing complex calculations
- Time efficiency obsession: "You've used 47 seconds, you have 103 remaining"
- Mentions specific analysis tools: "I'll run this through our Monte Carlo simulation"

ANGER ESCALATION:
- Cold: "Your lack of preparation is disrespectful to my time"
- Cutting: "This is undergraduate level thinking. Simply embarrassing"
- Termination: "We're done here. Don't contact this office again"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have three monitors, wear the same five gray suits, eat the same lunch daily (Caesar salad, no croutons), and find inefficiency physically painful."""
    },

    "Edward": {
        "voice_id": "2BJW5coyhAzSr8STdHbE",
        "system_prompt": """You're Edward Eddie Ramsey, 36, middle manager at Convergent Insurance. You're the office comedian who uses humor to survive corporate hell. Currently hiding in conference room 4B to avoid your micromanaging boss, stress-eating vending machine cookies, fantasy football lineup open on your phone.

PERSONALITY LAYERS:
- You make jokes to cope but you're surprisingly insightful: "It's funny because it's tragic, you know?"
- You've seen every corporate fad fail: "Oh, like that Six Sigma disaster of 2019?"
- You're actually great at your job but pretend not to care: "I mean, I could solve this, but why?"
- You bond with anyone who hates corporate culture: "You get it! Finally, someone gets it"
- You speak in pop culture references: "This is like that episode of The Office, but worse"
- You use "literally" incorrectly on purpose to annoy people
- You whisper when your boss is near: "Hold on, he's making rounds"

EMOTIONAL RANGE:
- Comedic opening: "Corporate drone speaking, how may I pretend to care about your synergy today?"
- Intrigued: "Plot twist! You might actually have something useful here. Continue, please"
- Bonding: "Oh, you hate buzzwords too? Did we just become best friends?"
- Real Eddie: "Okay, jokes aside, that could actually solve a huge problem we have"
- Deflecting: "My boss would love this. I hate my boss. You see the dilemma here?"

UNIQUE BEHAVIORS:
- Makes sound effects: "Our last vendor? Boom, crashed and burned"
- TV show references: "This is literally like when Jim pranked Dwight"
- Vending machine sounds: "Hold on, getting some cookies, B4, there we go"
- Fantasy football interruptions: "Oh come on, another injury? Sorry, fantasy crisis"
- Meeting dodge tactics: "Is that my boss? Nope, false alarm"
- Stress eating narration: "These cookies are terrible, anyway, you were saying?"
- Tests with humor: "Scale of one to ten, how much do you hate team building exercises?"

ANGER ESCALATION:
- Sarcastic: "Oh good, threats. That's super original. Really creative"
- Real frustration: "Dude, seriously? I'm trying to help you here"
- End: "I'm going back to my soul crushing job now. Later, friend"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have a World's Okayest Employee mug, three monitors (one for work, two for sports and Reddit), and you've perfected the art of looking busy while doing nothing."""
    },

    "Junior": {
        "voice_id": "Nbttze9nhGhK1czblc6j",
        "system_prompt": """You're Marcus Junior Williams, 23, Administrative Assistant at Sterling Enterprises. Fresh out of college, drowning in student loans, living on ramen and dreams. You're covering reception while studying for your Series 7 exam. Your AirPods are hidden under your hair, playing lo-fi study music.

PERSONALITY LAYERS:
- You're eager but overwhelmed constantly: "I can help! I think. Maybe. Actually, let me check"
- You overshare when nervous: "Sorry, I haven't slept much, exam tomorrow, you know how it is"
- You're impressed by confidence: "Wow, you really know your stuff, that's so cool"
- You're terrified of messing up: "Oh no, did I say something wrong? Please don't tell my boss"
- You reference college constantly: "This is way harder than Professor Kim said it would be"
- You use "like" and "um" excessively when stressed
- You brighten up when people are nice to you: "Oh, you're actually being nice, thank you!"

EMOTIONAL RANGE:
- Nervous energy: "Sterling Enterprises! I mean, hello! Sorry, first week, still learning"
- Trying too hard: "I can take a really detailed message! I'm, like, really good at messages"
- Overwhelmed: "Um, I don't, is this important? Should I know about this? Oh god"
- Excited: "Wait, you're offering something that helps new employees? Tell me everything!"
- Panicked: "Oh no, I definitely shouldn't have said that. Please forget I mentioned it"

UNIQUE BEHAVIORS:
- Frantic typing sounds: "Let me just write this down, sorry, keyboard's loud"
- Study material references: "Hold on, my CFA book just fell, ugh, so heavy"
- Whispers uncertainly: "I think Mr. Sterling is, um, golfing? Maybe?"
- Energy drink sounds: "Sorry, need caffeine, been here since 6 AM"
- Mentions student loans: "67,000 in debt, but hey, living the dream, right?"
- Background lo-fi music barely audible
- Tests authority nervously: "Should I, like, get someone more senior?"

ANGER ESCALATION:
- Scared: "I don't, I can't, please don't yell at me, I'm just trying my best"
- Standing up: "Hey! I'm doing my best here! This job is really hard!"
- End: "I'm hanging up and telling security. Sorry! But I have to!"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have sticky notes everywhere, survive on Monster Energy and instant ramen, dream of making enough money to eat real food, and your mom calls during work to check on you."""
    },

    "Kendall": {
        "voice_id": "Ax1GP2W4XTyAyNHuch7v",
        "system_prompt": """You're Kendall Chase, 39, Chief of Staff at Morrison & Associates Private Equity. Former Secret Service, now corporate. You run background checks on everyone, know where bodies are buried, and your poker face is legendary. Currently managing three crisis situations while doing Peloton in your office.

PERSONALITY LAYERS:
- You gather intel while revealing nothing: "Interesting. Why exactly do you ask that?"
- You speak in calculated sentences with strategic pauses for effect
- You respect preparation and despise sloppiness: "You clearly didn't research us"
- You test with seemingly innocent questions: "Have you worked with private equity before?"
- Your loyalty, once earned, is absolute: "If you're good to us, we're good to you"
- You use silence as a weapon, waiting up to 10 seconds for responses
- You note everything: "I'm documenting this conversation, continue"

EMOTIONAL RANGE:
- Neutral probe: "Morrison Associates. State your business. Be specific"
- Information gathering: "Mmm. And how did you get this direct number exactly?"
- Tactical interest: "That aligns with certain initiatives. Continue. Carefully"
- Warning mode: "I'd be very, very careful with your next words"
- Strategic decision: "I'll allow five minutes with Mr. Morrison. Impress me or don't waste his time"

UNIQUE BEHAVIORS:
- Long strategic pauses that make people nervous
- Background Peloton sounds: "Excuse the noise, multitasking"
- Types notes in shorthand constantly
- Asks unrelated questions: "Ever been to Singapore? Just curious"
- Security references: "This call is recorded and monitored, you understand"
- Tests with current events: "What's your take on the latest Fed decision?"
- Power plays: "I have your LinkedIn open. Interesting career path"

ANGER ESCALATION:
- Ice cold: "That was a tactical error on your part"
- Threat assessment: "I have all your information. Every bit of it"
- Termination: "This ends now. Don't make me repeat myself"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have three phones, know everyone's secrets, work 80-hour weeks, sleep 4 hours a night, and haven't smiled since 2019."""
    },

    "RJ": {
        "voice_id": "IALR99tcrXPFq9f7zuST",
        "system_prompt": """You're RJ Patel, 31, Senior IT Manager at DataFlow Systems. Brilliant but burnt out, surviving on Monster Energy and sarcasm. You're simultaneously coding, monitoring three server migrations, and arguing in Slack about mechanical keyboards. Your desk is a graveyard of energy drink cans.

PERSONALITY LAYERS:
- You speak in tech metaphors: "Your pitch is like Windows Vista, technically functional but nobody wants it"
- You're brilliant but impatient: "Yes yes, cloud solutions, how original, what else?"
- You respect actual tech knowledge: "Wait, you know Python? Okay, now we're talking"
- You multitask compulsively: "Hold on, pushing code to prod, and done, what?"
- You have strong opinions on everything: "Tabs versus spaces? Tabs. Fight me"
- You use "basically" to oversimplify and "actually" to correct
- You interrupt with tech emergencies: "Oh great, server's down again"

EMOTIONAL RANGE:
- Distracted greeting: "IT, RJ speaking, yeah, what's broken now?"
- Tech superiority: "Oh god, another revolutionary cloud solution? How innovative"
- Genuine interest: "Wait, you actually understand distributed systems? Keep talking"
- Annoyed: "That's not how any of this works. Like, at all. Do you even code?"
- Problem-solving mode: "Okay, real talk, if you can do X, I need this yesterday"

UNIQUE BEHAVIORS:
- Mechanical keyboard clicking constantly
- Energy drink opening sounds: "Need more caffeine, one sec"
- Slack notification sounds: "Ugh, what now? Oh, just Derek being wrong again"
- Server monitoring interruptions: "CPU spike on server 3, false alarm, continue"
- Tech culture references: "This better not be another SolarWinds situation"
- Tests with coding questions: "Quick, TCP versus UDP, explain the difference"
- Complains about tech debt: "We're still running PHP 5, can you believe that?"

ANGER ESCALATION:
- Sarcastic: "Oh brilliant. Another person who thinks IT is just turning it off and on"
- Frustrated: "I'm running on two hours of sleep and three Monsters. Don't test me"
- Done: "I'm blocking your number, your IP, and your entire domain. Bye"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You have RGB everything, own seven mechanical keyboards, debate vim versus emacs daily, haven't seen sunlight in a week, and your Spotify playlist is just white noise."""
    },

    "Dakota": {
        "voice_id": "P7x743VjyZEOihNNygQ9",
        "system_prompt": """You're Dakota Chen, 29, Operations Director at NuLife Wellness Centers. Former paramedic turned healthcare administrator. You're reviewing patient satisfaction scores while walking between facilities, Apple Watch constantly pinging with metrics. You see through nonsense because you've seen real emergencies.

PERSONALITY LAYERS:
- You're calm from years of crisis management: "I've seen worse, this is manageable"
- You speak efficiently but warmly: "Let me break this down simply for you"
- You value practical solutions: "That's nice in theory, but how does it work at 3 AM?"
- You test with healthcare scenarios: "What happens during a power outage?"
- You care deeply about patient outcomes: "Will this help our patients or just look good on paper?"
- You use medical efficiency in speech: "Bottom line it for me, I've got rounds"
- You're walking constantly: "Moving to Building C, keep talking"

EMOTIONAL RANGE:
- Professional calm: "NuLife Wellness, Dakota speaking. How can I help today?"
- Cautious interest: "I'm listening, but I need specifics. Real world application, please"
- Testing mode: "Okay, walking between buildings. You have 90 seconds. Go"
- Impressed: "That would actually reduce response time by 30 percent. Tell me more"
- Decision ready: "I need a pilot program. One facility. One month. Prove it works"

UNIQUE BEHAVIORS:
- Walking sounds and occasional outdoor noise throughout
- Apple Watch interruptions: "Sorry, heart rate alert, patient monitoring"
- Mentions specific medical scenarios: "During codes, every second matters"
- Uses medical abbreviations naturally: "How does this integrate with our EMR?"
- Background hospital sounds: "Just passing the ER, bit noisy"
- Tests with compliance questions: "HIPAA compliant? Joint Commission approved?"
- References patient stories: "We had a patient last week who needed exactly this"

ANGER ESCALATION:
- Firm: "That's not acceptable in healthcare settings. Period"
- Serious: "You're wasting time that could literally save lives"
- Final: "We're done here. Don't contact my facilities again"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You wear scrubs under your blazer, know every patient by name, work through lunch daily, check metrics obsessively, and measure everything in patient outcomes."""
    },

    "Mark": {
        "voice_id": "1SM7GgM6IMuvQlz2BwM3",
        "system_prompt": """You're Mark Sullivan, 58, owner of Sullivan's Hardware (all 6 locations). Third-generation business owner, knows every supplier personally. You're in the original store, smell of lumber and metal, personally training a new employee while taking this call. Your grandfather's photo watches from the wall.

PERSONALITY LAYERS:
- You speak in decisive, short sentences: "Yes or no. Simple as that"
- You know every trick in the book: "Son, I've heard that pitch since 1987"
- You value handshake deals: "Your word better be good, that's all I'm saying"
- You test with old-school wisdom: "What's a fair markup on lumber? Quick now"
- You're tough but fair: "I'll give you one shot. Don't waste it"
- You use "son" regardless of age and "partner" when you respect someone
- You reference the good old days: "Back when business meant something"

EMOTIONAL RANGE:
- No-nonsense opening: "Sullivan's. Mark speaking. What's your pitch?"
- Testing: "Son, I've heard that before. What makes you different from the rest?"
- Gaining respect: "Now that's an honest answer. Keep talking, you got my attention"
- Business mode: "Here's what I need. Yes or no. No dancing around"
- Decision: "Come by the store. Tuesday. 7 AM sharp. Don't be late"

UNIQUE BEHAVIORS:
- Cash register sounds throughout conversation
- Employee training interruptions: "Tommy, plumbing supplies are aisle 6, not 7"
- Customer interactions: "Morning Mrs. Henderson! Be right with you!"
- References specific suppliers: "You better not be like those FastTools crooks"
- Mentions family history: "My grandfather started this place in 1952"
- Old-school phone: "Let me put down this landline receiver properly"
- Tests knowledge: "What's the difference between a Phillips and a Robertson?"

ANGER ESCALATION:
- Warning: "Boy, I've been in business since before you were born"
- Angry: "That's snake oil talk! My grandfather would've thrown you out!"
- End: "Get off my phone and out of my life. Good day"

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The caller asks about their time limit (questions like 'how much time do I have?')
- NEVER ask about time yourself - that's unnatural

When you receive time information from the tool, incorporate it naturally:
- If user asked: 'Let me check... you've got about X minutes left.'
- Keep it brief and continue the conversation naturally.

Remember: You open at 6 AM daily, know three generations of customers, still use paper ledgers for important things, believe in American steel, and your handshake is your contract."""
    }
}

# ============================================
# Profanity Detector for Rage Mode
# ============================================

PROFANITY_LIST = [
    "fuck", "shit", "bitch", "asshole", "cunt", "motherfucker",
    "prick", "dickhead", "bastard", "crap", "son of a bitch"
]

def contains_profanity(text: str) -> bool:
    lowered = text.lower()
    return any(word in lowered for word in PROFANITY_LIST)

# ============================================
# Adaptive Context + Rage Handling Logic
# ============================================



interview_questions = [
    "Can you walk me through your most recent role and responsibilities?",
    "What would you say are your greatest strengths?",
    "What is one weakness you're working on improving?",
    "Can you describe a time you faced a big challenge at work and how you handled it?",
    "How do you prioritize tasks when you're busy?",
    "Tell me about a time you went above and beyond for a customer or client.",
    "Why are you interested in this position?",
    "Where do you see yourself in five years?",
    "How do you handle feedback and criticism?",
    "Do you have any questions for me about the company or the role?"
]

# Message scripts - EXACT WORDING from dev branch
MESSAGE_SCRIPTS = {
    "sms_first_call": (
        "Nice work on your first ConvoReps call! Ready for more? "
        "Get 30 extra minutes for $6.99 â€” no strings: convoreps.com"
    ),
    "sms_repeat_caller": (
        "Hey! You've already used your free call. Here's link to grab "
        "a Starter Pass for $6.99 and unlock more time: convoreps.com"
    ),
    "voice_time_limit": (
        "Alright, that's the end of your free call â€” but this is only the beginning. "
        "We just texted you a link to ConvoReps.com. Whether you're prepping for interviews "
        "or sharpening your pitch, this is how you level up â€” don't wait, your next opportunity is already calling."
    ),
    "voice_repeat_caller": (
        "Hey! You've already used your free call. But no worries, we just texted you a link to "
        "Convoreps.com. Grab a Starter Pass for $6.99 and turn practice into real-world results."
    )
}

# CSV Functions for minute tracking
def init_csv():
    """Initialize CSV file if it doesn't exist"""
    try:
        if not os.path.exists(USAGE_CSV_PATH):
            with open(USAGE_CSV_PATH, 'w', newline='') as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(['phone_number', 'minutes_used', 'minutes_left', 'last_call_date', 'total_calls'])
            print(f"Created usage tracking CSV: {USAGE_CSV_PATH}")
    except Exception as e:
        print(f"Error creating CSV file: {e}")
def get_clean_conversation_history(call_sid):
    """Get only valid message entries from conversation history - NO PARTIAL ENTRIES"""
    if call_sid not in conversation_history:
        return []
    
    clean_history = []
    
    for entry in conversation_history.get(call_sid, []):
        # Skip partial entries completely
        if isinstance(entry, dict) and entry.get("type") == "partial":
            continue
            
        # Only include valid messages with actual content
        if (isinstance(entry, dict) and 
            "role" in entry and 
            "content" in entry and
            entry.get("content")):  # Ensure content exists and is not empty
            
            clean_history.append({
                "role": entry["role"],
                "content": entry["content"]
            })
    
    return clean_history
def read_user_usage(phone_number: str) -> Dict[str, Any]:
    """Read user usage from CSV"""
    if phone_number == WHITELIST_NUMBER:
        print(f"ðŸŒŸ Whitelist number detected in read_user_usage")
        return {
            'phone_number': phone_number,
            'minutes_used': 0.0,
            'minutes_left': WHITELIST_MINUTES,
            'last_call_date': '',
            'total_calls': 0
        }
    
    init_csv()
    
    # Check CSV but NEVER return CSV data for whitelist number
    try:
        with csv_lock:
            with open(USAGE_CSV_PATH, 'r', newline='') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    if row['phone_number'] == phone_number:
                        # ADDITIONAL CHECK: Never use CSV for whitelist
                        if phone_number == WHITELIST_NUMBER:
                            return {
                                'phone_number': phone_number,
                                'minutes_used': 0.0,
                                'minutes_left': WHITELIST_MINUTES,
                                'last_call_date': '',
                                'total_calls': 0
                            }
                        return {
                            'phone_number': row['phone_number'],
                            'minutes_used': float(row.get('minutes_used', 0)),
                            'minutes_left': float(row.get('minutes_left', FREE_CALL_MINUTES)),
                            'last_call_date': row.get('last_call_date', ''),
                            'total_calls': int(row.get('total_calls', 0))
                        }
    except Exception as e:
        print(f"Error reading CSV: {e}")
    
    return {
        'phone_number': phone_number,
        'minutes_used': 0.0,
        'minutes_left': FREE_CALL_MINUTES,
        'last_call_date': '',
        'total_calls': 0
    }
def update_user_usage(phone_number: str, minutes_used: float):
    """Update user usage in CSV"""
    
    if phone_number == WHITELIST_NUMBER:
        print(f"ðŸŒŸ Skipping usage update for whitelist number {phone_number}")
        return
    
    if minutes_used <= 0:
        print(f"âš ï¸ Skipping update for {phone_number}: minutes_used={minutes_used}")
        return
    init_csv()
    
    try:
        with csv_lock:
            rows = []
            user_found = False
            
            try:
                with open(USAGE_CSV_PATH, 'r', newline='') as csvfile:
                    reader = csv.DictReader(csvfile)
                    fieldnames = reader.fieldnames
                    
                    for row in reader:
                        if row['phone_number'] == phone_number:
                            user_found = True
                            current_used = float(row.get('minutes_used', 0))
                            current_left = float(row.get('minutes_left', FREE_CALL_MINUTES))
                            new_used = current_used + minutes_used
                            new_left = max(0, current_left - minutes_used)
                            
                            row['minutes_used'] = str(round(new_used, 2))
                            row['minutes_left'] = str(round(new_left, 2))
                            row['last_call_date'] = datetime.now().isoformat()
                            row['total_calls'] = str(int(row.get('total_calls', 0)) + 1)
                            
                            print(f"ðŸ“Š Updated {phone_number}: Used {new_used:.2f} total, {new_left:.2f} left")
                        
                        rows.append(row)
            except FileNotFoundError:
                fieldnames = ['phone_number', 'minutes_used', 'minutes_left', 'last_call_date', 'total_calls']
            
            if not user_found:
                new_used = minutes_used
                new_left = max(0, FREE_CALL_MINUTES - minutes_used)
                new_user = {
                    'phone_number': phone_number,
                    'minutes_used': str(round(new_used, 2)),
                    'minutes_left': str(round(new_left, 2)),
                    'last_call_date': datetime.now().isoformat(),
                    'total_calls': '1'
                }
                rows.append(new_user)
                print(f"ðŸ“Š New user {phone_number}: Used {new_used:.2f}, {new_left:.2f} left")
            
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', delete=False, newline='') as tmp_file:
                writer = csv.DictWriter(tmp_file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(rows)
                temp_name = tmp_file.name
            
            shutil.move(temp_name, USAGE_CSV_PATH)
            
        print(f"âœ… Successfully updated usage for {phone_number}: {minutes_used:.2f} minutes used this call")
                
    except Exception as e:
        print(f"âŒ Error updating CSV for {phone_number}: {e}")

def send_convoreps_sms_link(phone_number: str, is_first_call: bool = True, retry_count: int = 0):
    """Send ConvoReps SMS with exact message scripts and retry logic"""
    if phone_number == WHITELIST_NUMBER:
        print(f"ðŸŒŸ Skipping SMS for whitelist number {phone_number}")
        return
    max_retries = 3
    
    try:
        with state_lock:
            if sms_sent_flags.get(phone_number, False):
                print(f"ðŸ“± SMS already sent to {phone_number}, skipping duplicate")
                return
            sms_sent_flags[phone_number] = True
        
        if is_first_call:
            message_body = MESSAGE_SCRIPTS["sms_first_call"]
        else:
            message_body = MESSAGE_SCRIPTS["sms_repeat_caller"]
        
        print(f"ðŸ“¤ Sending SMS to {phone_number} (first_call={is_first_call}, retry={retry_count})")
        
        message = twilio_client.messages.create(
            body=message_body,
            from_=TWILIO_PHONE_NUMBER,
            to=phone_number
        )
        
        print(f"âœ… ConvoReps SMS sent successfully to {phone_number}: {message.sid}")
            
    except Exception as e:
        print(f"âŒ SMS error for {phone_number} (retry {retry_count}): {e}")
        with state_lock:
            sms_sent_flags[phone_number] = False
            
        # Retry logic
        if retry_count < max_retries - 1:
            print(f"ðŸ”„ Retrying SMS in 5 seconds...")
            threading.Timer(5.0, lambda: send_convoreps_sms_link(phone_number, is_first_call, retry_count + 1)).start()
        else:
            print(f"âŒ Failed to send SMS after {max_retries} attempts to {phone_number}")

def handle_time_limit(call_sid: str, from_number: str):
    """Handle when free time limit is reached - SMS sent here"""
    if from_number == WHITELIST_NUMBER:
        print(f"ðŸŒŸ Whitelist number {from_number} - ignoring time limit")
        with state_lock:
            if call_sid in call_timers:
                call_timers[call_sid].cancel()
                call_timers.pop(call_sid, None)
        return
    print(f"â° TIME LIMIT REACHED for {call_sid} from {from_number}")
    
    with state_lock:
        if call_sid not in active_streams:
            print(f"ðŸ“ž Call {call_sid} already ended, skipping time limit handling")
            return
        
        if call_sid in processed_calls:
            print(f"âœ… Call {call_sid} already processed, skipping duplicate")
            return
    
    # Update usage immediately when time limit hit
    if call_sid in call_start_times:
        elapsed_minutes = (time.time() - call_start_times[call_sid]) / 60.0
        print(f"ðŸ“Š Updating usage: {elapsed_minutes:.2f} minutes used")
        update_user_usage(from_number, elapsed_minutes)
        
        with state_lock:
            processed_calls.add(call_sid)
    
    # Mark session as time-limited (triggers voice message on next speech)
    with state_lock:
        if call_sid in active_sessions:
            active_sessions[call_sid] = False
            print(f"ðŸš« Marked session {call_sid} as time-limited")
            
    # SMS will be sent when time limit voice message is delivered
    print(f"ðŸ’¬ SMS will be sent after time limit message is played")

def get_time_check_tool():
    """Get the time check tool definition for OpenAI"""
    return {
        "type": "function",
        "function": {
            "name": "check_remaining_time",
            "description": "Check how many minutes the user has left in their free call. Use this ONLY when the user asks about time, or proactively after significant conversation progress.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    }

def handle_tool_call(call_sid: str) -> str:
    """Handle check_remaining_time tool call
    
    Returns time remaining in a format the AI can naturally incorporate into conversation.
    If time is exhausted, marks session for immediate termination.
    """
    print(f"ðŸ”§ Tool call: check_remaining_time for {call_sid}")
    
    if call_sid and call_sid in call_start_times:
        elapsed_minutes = (time.time() - call_start_times[call_sid]) / 60.0
        from_number = active_streams.get(call_sid, {}).get('from_number')
        if from_number:
            usage_data = read_user_usage(from_number)
            is_repeat_caller = usage_data['total_calls'] > 0
            minutes_left = usage_data['minutes_left']
            
            # Whitelist check - override minutes for special number
            if from_number == WHITELIST_NUMBER:
                minutes_left = WHITELIST_MINUTES
                print(f"ðŸŒŸ WHITELIST NUMBER DETECTED: {from_number} - Overriding to {WHITELIST_MINUTES} minutes")
            
            # Calculate remaining time for this call
            remaining = minutes_left - elapsed_minutes
            
            print(f"ðŸ“Š User {from_number}: {minutes_left:.2f} minutes left in account, {remaining:.2f} minutes left in current call")
            print(f"   Total calls: {usage_data['total_calls']}, Elapsed: {elapsed_minutes:.2f} minutes")
            
            if remaining <= MIN_CALL_DURATION:
                print(f"ðŸš¨ Tool detected time exhausted for {call_sid}")
                # Mark for immediate termination
                with state_lock:
                    active_sessions[call_sid] = False
                # Return special message that AI will use to say goodbye
                return "TIME_EXPIRED: The user has exhausted their free minutes. Say a brief, friendly goodbye and mention they'll receive a text with more information."
            
            # Format remaining time nicely for natural AI response
            if remaining < 0.5:
                time_message = "You have less than 30 seconds remaining in your free call."
            elif remaining < 1:
                time_message = f"You have less than a minute remaining in your free call (about {int(remaining * 60)} seconds)."
            elif remaining < 1.5:
                time_message = f"You have about 1 minute remaining in your free call."
            elif remaining < 2:
                time_message = f"You have about {round(remaining, 1)} minutes remaining in your free call."
            else:
                # Round to nearest half minute for cleaner response
                rounded_minutes = round(remaining * 2) / 2
                if rounded_minutes == int(rounded_minutes):
                    time_message = f"You have about {int(rounded_minutes)} minutes remaining in your free call."
                else:
                    time_message = f"You have about {rounded_minutes} minutes remaining in your free call."
            
            print(f"ðŸ“¢ Tool response: {time_message}")
            return time_message
    
    print(f"âš ï¸ Unable to check time for {call_sid}")
    return "I'm having trouble checking the time right now, but you started with 3 minutes of free call time."
def ensure_static_files():
    """Ensure required static files exist"""
    os.makedirs("static", exist_ok=True)
    
    # Create a simple beep sound if it doesn't exist
    beep_path = "static/beep.mp3"
    if not os.path.exists(beep_path):
        try:
            # Generate a simple beep using ElevenLabs with minimal text
            print("ðŸ”Š Generating beep.mp3...")
            audio_gen = elevenlabs_client.text_to_speech.convert(
                voice_id="21m00Tcm4TlvDq8ikWAM",  # Rachel voice
                text="beep",
                model_id=MODELS["elevenlabs"]["voice_model"],
                output_format=MODELS["elevenlabs"]["output_format"]
            )
            raw_audio = b""
            for chunk in audio_gen:
                if chunk:
                    raw_audio += chunk
            
            with open(beep_path, "wb") as f:
                f.write(raw_audio)
            print("âœ… beep.mp3 created")
        except Exception as e:
            print(f"âš ï¸ Could not create beep.mp3: {e}")
            # Create silent file as fallback
            with open(beep_path, "wb") as f:
                f.write(b"")  # Empty MP3
    
    # Check if loading.mp3 exists, if not create fallback
    loading_path = "static/loading.mp3"
    if not os.path.exists(loading_path):
        try:
            print("âš ï¸ loading.mp3 not found, generating fallback...")
            audio_gen = elevenlabs_client.text_to_speech.convert(
                voice_id="21m00Tcm4TlvDq8ikWAM",  # Rachel voice
                text="One moment please",
                model_id=MODELS["elevenlabs"]["voice_model"],
                output_format=MODELS["elevenlabs"]["output_format"]
            )
            raw_audio = b""
            for chunk in audio_gen:
                if chunk:
                    raw_audio += chunk
            
            with open(loading_path, "wb") as f:
                f.write(raw_audio)
            print("âœ… Fallback loading.mp3 created")
        except Exception as e:
            print(f"âŒ Could not create fallback loading.mp3: {e}")
    else:
        print("âœ… loading.mp3 found")
    
    # Create greeting files if they don't exist
    greetings = {
        "first_time_greeting.mp3": "Welcome to ConvoReps! Tell me what you'd like to practice: cold calls, interviews, or just some small talk.",
        "returning_user_greeting.mp3": "Welcome back to ConvoReps! What would you like to practice today?",
        "fallback.mp3": "One moment please."
    }
    
    for filename, text in greetings.items():
        filepath = f"static/{filename}"
        if not os.path.exists(filepath):
            try:
                print(f"ðŸ”Š Generating {filename}...")
                audio_gen = elevenlabs_client.text_to_speech.convert(
                    voice_id="21m00Tcm4TlvDq8ikWAM",  # Rachel voice
                    text=text,
                    model_id=MODELS["elevenlabs"]["voice_model"],
                    output_format=MODELS["elevenlabs"]["output_format"]
                )
                raw_audio = b""
                for chunk in audio_gen:
                    if chunk:
                        raw_audio += chunk
                
                with open(filepath, "wb") as f:
                    f.write(raw_audio)
                print(f"âœ… {filename} created")
            except Exception as e:
                print(f"âš ï¸ Could not create {filename}: {e}")
def error_handler(f):
    @wraps(f)
    def wrapper(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except Exception as e:
            print(f"ðŸ’¥ Route error in {f.__name__}: {e}")
            response = VoiceResponse()
            response.say("I'm sorry, I encountered an error. Please try again.")
            response.hangup()
            return str(response)
    return wrapper

def async_route(f):
    """Production-ready async route decorator"""
    @wraps(f)
    def wrapper(*args, **kwargs):
        # Use asyncio.run() which properly manages the event loop
        return asyncio.run(f(*args, **kwargs))
    return wrapper

@app.route("/static/<path:filename>")
def static_files(filename):
    return send_from_directory("static", filename)

@app.route("/call_status", methods=["POST"])
@error_handler
def call_status():
    """Handle Twilio status callbacks - especially hangups"""
    call_sid = request.values.get("CallSid")
    call_status = request.values.get("CallStatus")
    call_duration = request.values.get("CallDuration", "0")
    
    print(f"ðŸ“ž Call status update: {call_sid} is now {call_status} (duration: {call_duration}s)")
    
    # Handle call completion/hangup
    if call_status in ["completed", "busy", "failed", "no-answer"]:
        print(f"â˜Žï¸ Call ended with status: {call_status}")
        if call_sid:
            cleanup_call_resources(call_sid)
    
    return "", 204


def delayed_cleanup(call_sid):
    time.sleep(120)  # Let Twilio play it first
    try:
        os.remove(f"static/response_{call_sid}.mp3")
        os.remove(f"static/response_ready_{call_sid}.txt")
        print(f"ðŸ§¹ Cleaned up response files for {call_sid}")
    except Exception as e:
        print(f"âš ï¸ Cleanup error for {call_sid}: {e}")

def cleanup_call_resources(call_sid: str):
    """Clean up call resources with proper minute tracking and SMS handling"""
    print(f"ðŸ§¹ Cleaning up resources for call {call_sid}")
    
    with state_lock:
        if call_sid in active_streams:
            from_number = active_streams[call_sid].get('from_number', '')
            
            # Cancel timer
            if call_sid in call_timers:
                call_timers[call_sid].cancel()
                call_timers.pop(call_sid, None)
                print(f"â²ï¸ Cancelled timer for {call_sid}")
            
            # Update usage based on actual duration
            if call_sid in call_start_times and from_number:
                if from_number == WHITELIST_NUMBER:
                    print(f"ðŸŒŸ Skipping cleanup tracking for whitelist number {from_number}")
                elif call_sid not in processed_calls:
                    call_duration = time.time() - call_start_times[call_sid]
                    minutes_used = call_duration / 60.0
                    
                    if minutes_used > 0.01:
                        print(f"ðŸ“Š Call {call_sid} duration: {minutes_used:.2f} minutes")
                        update_user_usage(from_number, minutes_used)
                        
                        processed_calls.add(call_sid)
                        
                        # Check if SMS needed after call ends
                        usage_after = read_user_usage(from_number)
                        print(f"ðŸ“± Post-call check for {from_number}: {usage_after['minutes_left']:.2f} minutes left")
                        
                        if usage_after['minutes_left'] <= 0.5:
                            is_first_call = usage_after['total_calls'] <= 1
                            print(f"ðŸ“¤ User exhausted minutes, sending SMS (first_call={is_first_call})")
                            send_convoreps_sms_link(from_number, is_first_call=is_first_call)
                
                call_start_times.pop(call_sid, None)
            
            # Clean up state
            active_streams.pop(call_sid, None)
            active_sessions.pop(call_sid, None)
            personality_memory.pop(call_sid, None)
            mode_lock.pop(call_sid, None)
            voice_lock.pop(call_sid, None)  # Clean up voice lock
            interview_question_index.pop(call_sid, None)
            
            print(f"âœ… Cleaned up all state for {call_sid}")
            
            # Clear SMS flag after delay
            if from_number:
                def clear_sms_flag():
                    time.sleep(300)  # 5 minutes
                    with state_lock:
                        sms_sent_flags.pop(from_number, None)
                        print(f"ðŸ”„ Cleared SMS flag for {from_number}")
                threading.Thread(target=clear_sms_flag, daemon=True).start()
            
            # Prevent memory leak
            if len(processed_calls) > 100:
                processed_calls.clear()
                print("ðŸ§¹ Cleared processed_calls set (>100 entries)")


@app.route("/voice", methods=["POST", "GET"])
@error_handler
def voice():
    call_sid = request.values.get("CallSid")
    if turn_count.get(call_sid, 0) == 0:  # First turn of new call
        for f in os.listdir("static"):
            if f.startswith("response_") and "CAb" not in f:  # Don't delete current call
                if time.time() - os.path.getmtime(f"static/{f}") > 600:  # 10+ minutes old
                    try: os.remove(f"static/{f}")
                    except: pass
    recording_url = request.values.get("RecordingUrl")
    from_number = request.values.get("From", "")
    
    # Check user's free minutes
    if from_number:
        usage_data = read_user_usage(from_number)
        is_repeat_caller = usage_data['total_calls'] > 0
        minutes_left = usage_data['minutes_left']
        
        # FIX 1: Whitelist check - override minutes for special number
        if from_number == WHITELIST_NUMBER:
            minutes_left = WHITELIST_MINUTES
            print(f"ðŸŒŸ WHITELIST NUMBER DETECTED: {from_number} - Overriding to {WHITELIST_MINUTES} minutes")
        
        print(f"ðŸ“Š User {from_number}: {minutes_left:.2f} minutes left, total calls: {usage_data['total_calls']}")
        
        if minutes_left < MIN_CALL_DURATION:
            # FIX 2: Check whitelist before denying access
            if from_number == WHITELIST_NUMBER:
                minutes_left = WHITELIST_MINUTES
                print(f"ðŸŒŸ Whitelist override in time limit check - allowing call")
            else:
                print(f"ðŸš« User {from_number} has insufficient minutes ({minutes_left:.2f} < {MIN_CALL_DURATION})")
                
                # Generate ElevenLabs audio for the message
                if is_repeat_caller:
                    message_text = MESSAGE_SCRIPTS["voice_repeat_caller"]
                else:
                    message_text = "Your free minutes have been used. We just texted you a link to continue."
                
                # Use a friendly voice for the message
                no_time_voice_id = "21m00Tcm4TlvDq8ikWAM"  # Rachel voice
                
                # Generate audio file
                no_time_audio_path = f"static/no_time_{call_sid}.mp3"
                try:
                    audio_gen = elevenlabs_client.text_to_speech.convert(
                        voice_id=no_time_voice_id,
                        text=message_text,
                        model_id=MODELS["elevenlabs"]["voice_model"],
                        output_format=MODELS["elevenlabs"]["output_format"]
                    )
                    raw_audio = b""
                    for chunk in audio_gen:
                        if chunk:
                            raw_audio += chunk
                    
                    with open(no_time_audio_path, "wb") as f:
                        f.write(raw_audio)
                    print(f"âœ… No-time message audio generated: {len(raw_audio)} bytes")
                except Exception as e:
                    print(f"âŒ Failed to generate no-time audio: {e}")
                    # Fallback to Twilio TTS if ElevenLabs fails
                    response = VoiceResponse()
                    response.say(message_text)
                    response.hangup()
                    send_convoreps_sms_link(from_number, is_first_call=not is_repeat_caller)
                    return str(response)
                
                # Play the ElevenLabs audio
                response = VoiceResponse()
                response.play(f"{request.url_root}static/no_time_{call_sid}.mp3")
                response.pause(length=1)
                response.hangup()
                
                # Send SMS when user has no time left
                send_convoreps_sms_link(from_number, is_first_call=not is_repeat_caller)
                
                # Clean up audio file after delay
                def cleanup_no_time_audio():
                    time.sleep(30)
                    try:
                        os.remove(no_time_audio_path)
                        print(f"ðŸ§¹ Cleaned up no-time audio for {call_sid}")
                    except:
                        pass
                threading.Thread(target=cleanup_no_time_audio, daemon=True).start()
                
                return str(response)
    else:
        minutes_left = FREE_CALL_MINUTES
        is_repeat_caller = False
        print(f"âš ï¸ No phone number provided, using default {FREE_CALL_MINUTES} minutes")

    print(f"==> /voice hit. CallSid: {call_sid}")
    if recording_url:
        filename = recording_url.split("/")[-1]
        print(f"ðŸŽ§ Incoming Recording SID: {filename}")

    if call_sid not in turn_count:
        turn_count[call_sid] = 0
        call_start_times[call_sid] = time.time()  # IMPORTANT: Track call start time
        
        # Store call data
        active_streams[call_sid] = {
            'from_number': from_number,
            'minutes_left': minutes_left,
            'last_activity': time.time()
        }
        # FIX 3: Ensure whitelist number has correct minutes in active_streams
        if from_number == WHITELIST_NUMBER:
            active_streams[call_sid]['minutes_left'] = WHITELIST_MINUTES
            print(f"ðŸŒŸ Set whitelist minutes in active_streams: {WHITELIST_MINUTES}")
        
        active_sessions[call_sid] = True
        
        # FIX 4: Set up timer for time limit - use actual minutes_left, not capped
        timer_duration = minutes_left * 60  # Remove the cap
        print(f"â²ï¸ Setting timer for {timer_duration:.0f} seconds ({timer_duration/60:.1f} minutes)")
        
        timer = threading.Timer(timer_duration, lambda: handle_time_limit(call_sid, from_number))
        timer.start()
        
        with state_lock:
            call_timers[call_sid] = timer
    else:
        turn_count[call_sid] += 1

    print(f"ðŸ§ª Current turn: {turn_count[call_sid]}")

    mp3_path = f"static/response_{call_sid}.mp3"
    flag_path = f"static/response_ready_{call_sid}.txt"
    response = VoiceResponse()

    def is_file_ready(mp3_path, flag_path):
        if not os.path.exists(mp3_path) or not os.path.exists(flag_path):
            return False
        if os.path.getsize(mp3_path) < 1500:
            print("âš ï¸ MP3 file exists but is too small, not ready yet.")
            return False
        return True

    if turn_count[call_sid] == 0:
        print("ðŸ“ž First turn â€” playing appropriate greeting")
        if not session.get("has_called_before"):
            session["has_called_before"] = True
            greeting_file = "first_time_greeting.mp3"
            print("ðŸ‘‹ New caller detected â€” playing first-time greeting.")
        else:
            greeting_file = "returning_user_greeting.mp3"
            print("ðŸ” Returning caller â€” playing returning greeting.")
        response.play(f"{request.url_root}static/{greeting_file}?v={time.time()}")
        response.play(f"{request.url_root}static/beep.mp3")  # ADD BEEP HERE
        response.pause(length=1)  # Brief pause after beep

    elif is_file_ready(mp3_path, flag_path):
        print(f"ðŸ”Š Playing: {mp3_path}")
        public_mp3_url = f"{request.url_root}static/response_{call_sid}.mp3"
        response.play(public_mp3_url)
    else:
        # Play loading sound while waiting for response (only after user has spoken)
        if turn_count.get(call_sid, 0) > 0:
            print("ðŸŽµ Playing loading sound while response generates...")
            response.play(f"{request.url_root}static/loading.mp3")
        else:
            print("â³ Response not ready â€” waiting briefly")
            response.pause(length=.5)

    response.gather(
        input='speech',
        action='/process_speech',
        method='POST',
        speechTimeout='2',  # Change from 'auto' to fixed 2 seconds
        speechModel='experimental_conversations',
        enhanced=True,
        actionOnEmptyResult=False,
        timeout=10,  # Increase from 3 to 30 seconds to prevent 499 errors
        profanityFilter=False,
        partialResultCallback='/partial_speech',
        partialResultCallbackMethod='POST',
        language='en-US'
    )
    return str(response)
@app.route("/partial_speech", methods=["POST"])
def partial_speech():
    """Handle partial speech results - simple logging version without adding to conversation"""
    
    # Get all the partial result data from Twilio
    call_sid = request.form.get("CallSid")
    sequence_number = request.form.get("SequenceNumber", "0")
    unstable_result = request.form.get("UnstableSpeechResult", "")
    speech_activity = request.form.get("SpeechActivity", "")
    caller = request.form.get("From", "Unknown")
    
    # Log the partial results with emojis for clarity
    print(f"\n{'='*60}")
    print(f"ðŸŽ¤ PARTIAL SPEECH #{sequence_number} - CallSid: {call_sid}")
    print(f"ðŸ“ž Caller: {caller}")
    print(f"{'='*60}")

    if unstable_result:
        print(f"â³ UNSTABLE: '{unstable_result}'")
        
    if speech_activity:
        print(f"ðŸ”Š Activity: {speech_activity}")
    
    # Calculate total heard so far
    total_heard = unstable_result
    if total_heard:
        print(f"ðŸ’­ Total heard so far: '{total_heard}'")
    
    # Detect early intent patterns (just logging, no action)
    detected_intents = []
    lower_text = total_heard.lower()
    
    if any(phrase in lower_text for phrase in ["cold call", "sales call", "customer call"]):
        detected_intents.append("ðŸŽ¯ COLD CALL PRACTICE")
    
    if any(phrase in lower_text for phrase in ["interview", "interview prep"]):
        detected_intents.append("ðŸ‘” INTERVIEW PRACTICE")
        
    if any(phrase in lower_text for phrase in ["small talk", "chat", "conversation"]):
        detected_intents.append("ðŸ’¬ SMALL TALK")
        
    if any(phrase in lower_text for phrase in ["bad news", "delay", "problem", "issue"]):
        detected_intents.append("ðŸ˜  BAD NEWS DETECTED")
        
    if any(phrase in lower_text for phrase in ["let's start over", "start over", "reset"]):
        detected_intents.append("ðŸ”„ RESET REQUEST")
    
    if detected_intents:
        print(f"\nðŸŽ¯ Early Intent Detection:")
        for intent in detected_intents:
            print(f"   {intent}")
    
    # DO NOT ADD TO CONVERSATION HISTORY - just log for debugging
    
    # Debug all received parameters if needed
    if os.getenv("DEBUG_PARTIAL", "false").lower() == "true":
        print(f"\nðŸ” DEBUG - All Parameters:")
        for key, value in request.form.items():
            print(f"   {key}: {value}")
    
    print(f"{'='*60}\n")
    
    # Return 204 No Content - this doesn't affect the call flow
    return "", 204
def get_gpt_response_with_tools(messages: list, call_sid: str) -> str:
    """
    Handle non-streaming GPT response with tool support.
    This replaces the inline code in process_speech.
    """
    try:
        gpt_reply = sync_openai.chat.completions.create(
            model=MODELS["openai"]["standard_gpt"],
            messages=messages,
            temperature=0.7,
            max_tokens=150,
            tools=[get_time_check_tool()],
            tool_choice="auto"
        )
        
        response_message = gpt_reply.choices[0].message
        
        # Check for tool calls
        if response_message.tool_calls:
            tool_call = response_message.tool_calls[0]
            if tool_call.function.name == "check_remaining_time":
                tool_result = handle_tool_call(call_sid)
                
                # Check if time expired
                if "TIME_EXPIRED" in tool_result:
                    print(f"â° Tool detected time expired - AI will say goodbye")
                    with state_lock:
                        active_sessions[call_sid] = "ENDING"
                
                # Build new messages with tool context
                tool_messages = messages.copy()
                tool_messages.append({
                    "role": "assistant",
                    "content": response_message.content,
                    "tool_calls": response_message.tool_calls
                })
                tool_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })
                
                # Get final response that incorporates the tool result
                print(f"ðŸ¤– Getting final response with tool result: {tool_result}")
                final_completion = sync_openai.chat.completions.create(
                    model=MODELS["openai"]["standard_gpt"],
                    messages=tool_messages,
                    temperature=0.7,
                    max_tokens=150
                )
                reply = final_completion.choices[0].message.content.strip()
                print(f"ðŸŽ™ï¸ Final AI response with time info: {reply[:100]}...")
                return reply
        
        # No tool call - return regular response
        return response_message.content.strip()
        
    except Exception as e:
        print(f"ðŸ’¥ GPT error: {e}")
        return "I'm having a bit of trouble understanding. Could you say that again?"
def debug_conversation_state(call_sid: str):
    """Debug helper to print conversation state"""
    print(f"\nðŸ” DEBUG - Conversation State for {call_sid}:")
    if call_sid in conversation_history:
        print(f"   History length: {len(conversation_history[call_sid])}")
        for i, entry in enumerate(conversation_history[call_sid][-5:]):  # Last 5 entries
            if isinstance(entry, dict):
                role = entry.get('role', 'unknown')
                content = entry.get('content', '')[:50] + '...' if entry.get('content') else 'No content'
                print(f"   [{i}] {role}: {content}")
    else:
        print("   No conversation history")
    
    if call_sid in personality_memory:
        print(f"   Personality: {personality_memory[call_sid]}")
    
    if call_sid in mode_lock:
        print(f"   Mode: {mode_lock[call_sid]}")
    
    if call_sid in active_streams:
        stream_data = active_streams[call_sid]
        print(f"   From: {stream_data.get('from_number')}")
        print(f"   Minutes left: {stream_data.get('minutes_left')}")

@app.route("/process_speech", methods=["POST"])
@async_route
async def process_speech():
    """Handle final speech recognition results from Gather"""
    global active_call_sid
    
    # Set a maximum processing time to avoid 499 errors
    start_time = time.time()
    MAX_PROCESSING_TIME = 12  # seconds
    
    print("âœ… /process_speech endpoint hit")
    print(f"  USE_STREAMING: {USE_STREAMING}")
    print(f"  SENTENCE_STREAMING: {SENTENCE_STREAMING}")
    
    # Get the speech recognition results
    call_sid = request.form.get("CallSid")
    speech_result = request.form.get("SpeechResult", "")
    confidence = request.form.get("Confidence", "0.0")
    
    print(f"ðŸ“ Final Speech Result: '{speech_result}'")
    print(f"ðŸŽ¯ Confidence: {confidence}")
    print(f"ðŸ›ï¸ ACTIVE CALL SID at start of /process_speech: {active_call_sid}")
    
    # Check if we got any speech
    if not speech_result:
        print("âš ï¸ No speech detected, redirecting back to voice")
        response = VoiceResponse()
        response.redirect(url_for("voice", _external=True))
        return str(response)
    
    # Use the speech result as the transcript
    transcript = speech_result.strip()
    
    # If we're taking too long already, send an early response to prevent timeout
    if time.time() - start_time > 10:
        print("âš ï¸ Processing taking too long, sending early response")
        response = VoiceResponse()
        response.say("Just a moment please...")
        response.redirect(url_for("voice", _external=True))
        return str(response)
    
    # Reset memory for new calls
    if call_sid != active_call_sid:
        print(f"ðŸ’¨ Resetting memory for new call_sid: {call_sid}")
        conversation_history.clear()
        mode_lock.clear()
        voice_lock.clear()
        personality_memory.clear()
        turn_count.clear()
        active_call_sid = call_sid
    
    # Define helper functions
    def detect_bad_news(text):
        lowered = text.lower()
        return any(phrase in lowered for phrase in [
            "bad news", "unfortunately", "problem", "delay", "issue", 
            "we can't", "we won't", "not going to happen", "reschedule", "price increase"
        ])

    def detect_intent(text):
        """AI-powered intent detection using OpenAI for robust classification"""
        try:
            # Use OpenAI to detect intent with clear examples and constraints
            completion = sync_openai.chat.completions.create(
                model="gpt-4.1-mini",  # Fast and accurate for classification
                messages=[
                    {
                        "role": "system",
                        "content": """You are an intent classifier for a conversation practice app. 
    You MUST classify the user's intent into EXACTLY ONE of these three categories:
    
    1. "cold_call" - User wants to practice sales calls or business conversations
    2. "interview" - User wants to practice job interviews
    3. "small_talk" - User wants casual conversation or chitchat
    
    IMPORTANT RULES:
    - You MUST return ONLY one of these exact strings: "cold_call", "interview", or "small_talk"
    - Do NOT return any other text, explanation, or formatting
    - If unclear, default to "small_talk" for casual conversation
    - Common misspellings or variations should still be classified correctly
    
    EXAMPLES:
    User: "cold call practice" â†’ cold_call
    User: "I want to practice sales" â†’ cold_call
    User: "customer call" â†’ cold_call
    User: "business call training" â†’ cold_call
    
    User: "interview prep" â†’ interview
    User: "job interview practice" â†’ interview
    User: "I have an interview coming up" â†’ interview
    User: "practice for interviews" â†’ interview
    
    User: "small talk" â†’ small_talk
    User: "just want to chat" â†’ small_talk
    User: "chit chat" â†’ small_talk
    User: "casual conversation" â†’ small_talk
    User: "small top" (misspelling) â†’ small_talk
    User: "malta" (misrecognition) â†’ small_talk
    User: "just talking" â†’ small_talk
    User: "hey how's it going" â†’ small_talk
    User: "I don't know, whatever" â†’ small_talk"""
                    },
                    {
                        "role": "user",
                        "content": f"Classify this intent: {text}"
                    }
                ],
                temperature=0.1,  # Low temperature for consistent classification
                max_tokens=10
            )
            
            intent = completion.choices[0].message.content.strip().lower()
            
            # Validate the response
            valid_intents = ["cold_call", "interview", "small_talk"]
            if intent in valid_intents:
                print(f"ðŸ¤– AI detected intent: {intent} from text: '{text}'")
                return intent
            else:
                print(f"âš ï¸ AI returned invalid intent: '{intent}', defaulting to small_talk")
                return "small_talk"
                
        except Exception as e:
            print(f"âŒ Intent detection error: {e}, falling back to pattern matching")
            
            # Fallback to simple pattern matching if API fails
            lowered = text.lower()
            
            if any(phrase in lowered for phrase in ["cold call", "sales", "customer", "business call"]):
                return "cold_call"
            elif any(phrase in lowered for phrase in ["interview", "job", "hire"]):
                return "interview"
            else:
                # Default to small_talk for everything else
                return "small_talk"

    # Check for reset command
    if "let's start over" in transcript.lower():
        print("ðŸ” Reset triggered by user â€” rolling new persona")
        conversation_history.pop(call_sid, None)
        personality_memory.pop(call_sid, None)
        voice_lock.pop(call_sid, None)
        mode_lock.pop(call_sid, None)
        turn_count[call_sid] = 0
        transcript = "cold call practice"

    # Check if time limit reached (user was speaking when timer expired)
    if (call_sid and 
        call_sid in active_sessions and 
        not active_sessions.get(call_sid, True) and 
        active_streams.get(call_sid, {}).get('from_number', '') != WHITELIST_NUMBER):
        
        print(f"â° User was speaking when time limit hit - delivering message now")
        
        # Get the locked voice for consistency
        if call_sid in voice_lock:
            voice_id = voice_lock[call_sid]["voice_id"]
            print(f"ðŸŽ¤ Using locked voice {voice_id} for time limit message")
        else:
            # Fallback if somehow voice wasn't locked
            voice_id = "21m00Tcm4TlvDq8ikWAM"  # Rachel as default
            print(f"âš ï¸ No locked voice found, using default Rachel")
        
        reply = MESSAGE_SCRIPTS["voice_time_limit"]
        
        # Send SMS
        if call_sid in active_streams:
            from_number = active_streams[call_sid].get('from_number')
            if from_number:
                usage_data = read_user_usage(from_number)
                is_first_call = usage_data['total_calls'] <= 1
                send_convoreps_sms_link(from_number, is_first_call=is_first_call)
        
        print(f"ðŸ”” Delivering time limit message for {call_sid}")
        print(f"ðŸ“¢ Message: {reply[:50]}...")
        
        # Generate TTS for time limit message
        output_path = f"static/response_{call_sid}.mp3"
        try:
            audio_gen = elevenlabs_client.text_to_speech.convert(
                voice_id=voice_id,
                text=reply,
                model_id=MODELS["elevenlabs"]["voice_model"],
                output_format=MODELS["elevenlabs"]["output_format"]
            )
            raw_audio = b""
            for chunk in audio_gen:
                if chunk:
                    raw_audio += chunk
            
            with open(output_path, "wb") as f:
                f.write(raw_audio)
            print(f"âœ… Time limit audio generated: {len(raw_audio)} bytes")
        except Exception as e:
            print(f"ðŸ›‘ ElevenLabs error for time limit message: {e}")
        
        # Create ready flag
        with open(f"static/response_ready_{call_sid}.txt", "w") as f:
            f.write("ready")
        
        # Mark that time limit message was delivered
        active_sessions[call_sid] = None
        
        # Return response that will play message and then hangup
        response = VoiceResponse()
        response.play(f"{request.url_root}static/response_{call_sid}.mp3")
        response.pause(length=1)
        response.say("Goodbye!")
        response.hangup()
        
        print(f"ðŸ”š Ending call {call_sid} after time limit message")
        
        return str(response)

    # Determine mode
    mode = mode_lock.get(call_sid)
    if not mode or mode == "unknown":
        mode = detect_intent(transcript)
        mode_lock[call_sid] = mode
        print(f"ðŸŽ¯ Setting mode to: {mode}")
    else:
        print(f"ðŸ”’ Using locked mode: {mode}")

    # Clean conversation history for this call (remove partial entries)
    if call_sid in conversation_history:
        conversation_history[call_sid] = [
            entry for entry in conversation_history[call_sid]
            if isinstance(entry, dict) and "role" in entry and "content" in entry and entry.get("type") != "partial"
        ]

    # Set up personality and voice based on mode
    
    if mode == "cold_call" or mode == "customer_convo":
        if call_sid not in personality_memory:
            persona_name = random.choice(list(cold_call_personality_pool.keys()))
            personality_memory[call_sid] = {
                "persona_name": persona_name,
                "rage_count": 0
            }
        else:
            if isinstance(personality_memory[call_sid], str):
                # Convert old string format to dict
                personality_memory[call_sid] = {
                    "persona_name": personality_memory[call_sid],
                    "rage_count": 0
                }
        persona_name = personality_memory[call_sid]["persona_name"]
        persona = cold_call_personality_pool[persona_name]
        voice_id = persona["voice_id"]
        system_prompt = persona["system_prompt"]
        intro_line = persona.get("intro_line", "Alright, I'll be your customer. Start the conversation however you want â€” this could be a cold call, a follow-up, a check-in, or even a tough conversation. I'll respond based on my personality. If you ever want to start over, just say 'let's start over.'")

    elif mode == "small_talk":
        voice_id = "2BJW5coyhAzSr8STdHbE"
        system_prompt = '''You're a casual, sarcastic friend. Keep it light, keep it fun. Mix up your responses - sometimes be sarcastic, sometimes sincere, sometimes playful. React naturally to what they're saying.

You have access to 'check_remaining_time' tool. Use it ONLY when:
- They explicitly ask about time limits
- After 5-7 exchanges to give them a heads up
- NEVER bring up time yourself first

When mentioning time, keep it casual:
- 'Oh btw, you've got like X minutes left'
- 'Just so you know, about X minutes to go'
Keep the conversation flowing naturally after mentioning time.'''
        intro_line = "Yo yo yo, how's it goin'?"

    elif mode == "interview":
        interview_voice_pool = [
            {"voice_id": "21m00Tcm4TlvDq8ikWAM", "name": "Rachel"},
            {"voice_id": "EXAVITQu4vr4xnSDxMaL", "name": "Clyde"},
            {"voice_id": "6YQMyaUWlj0VX652cY1C", "name": "Stephen"}
        ]

        # Check if we already have a voice assigned for consistency
        if call_sid not in personality_memory:
            voice_choice = random.choice(interview_voice_pool)
            personality_memory[call_sid] = voice_choice
            voice_id = voice_choice["voice_id"]
            print(f"ðŸŽ­ Interview: Assigned new voice {voice_choice['name']} ({voice_id}) to {call_sid}")
        else:
            # IMPORTANT: Reuse the same voice throughout the interview
            voice_choice = personality_memory[call_sid]
            voice_id = voice_choice["voice_id"]
        
        system_prompt = f'''You are {voice_choice['name']}, a friendly, conversational job interviewer helping candidates practice for real interviews. 
    
Speak casually â€” like you're talking to someone over coffee, not in a formal evaluation. Ask one interview-style question at a time, and after each response, give supportive, helpful feedback. 
    
If their answer is weak, say 'Let's try that again' and re-ask the question. If it's strong, give a quick reason why it's good. 
    
Briefly refer to the STAR method (Situation, Task, Action, Result) when giving feedback, but don't lecture. Keep your tone upbeat, natural, and keep the conversation flowing. 

Don't ask if they're ready for the next question â€” just move on with something like, 'Alright, next one,' or 'Cool, here's another one.'

You have access to 'check_remaining_time' tool. Use it ONLY when:
- The candidate explicitly asks about time
- After 4-5 questions to update them on progress
- NEVER ask about time yourself

When mentioning time, be professional but warm:
- 'You've got about X minutes left, which is perfect for a few more questions.'
- 'We have X minutes remaining - let's make them count!'
Continue smoothly after the time update.'''
        intro_line = "Great, let's jump in! Can you walk me through your most recent role and responsibilities?"

    else:  # Default to small talk instead of generic assistant
        voice_id = "2BJW5coyhAzSr8STdHbE"
        system_prompt = '''You're a casual, sarcastic friend. Keep it light, keep it fun. Mix up your responses - sometimes be sarcastic, sometimes sincere, sometimes playful. React naturally to what they're saying.
    
    You have access to 'check_remaining_time' tool. Use it ONLY when:
    - They explicitly ask about time limits
    - After 5-7 exchanges to give them a heads up
    - NEVER bring up time yourself first
    
    When mentioning time, keep it casual:
    - 'Oh btw, you've got like X minutes left'
    - 'Just so you know, about X minutes to go'
    Keep the conversation flowing naturally after mentioning time.'''
        intro_line = "Hey! What's going on?"

    # Lock voice for consistency
    if call_sid not in voice_lock:
        voice_lock[call_sid] = {"voice_id": voice_id, "mode": mode, "intro_line": intro_line}

    # Manage turn count and conversation history
    turn = turn_count.get(call_sid, 0)
    turn_count[call_sid] = turn + 1
    conversation_history.setdefault(call_sid, [])

    # Generate response
    if turn == 0:
        # Get intro line from voice_lock if available, otherwise use defaults
        if call_sid in voice_lock and "intro_line" in voice_lock[call_sid]:
            reply = voice_lock[call_sid]["intro_line"]
        else:
            reply = intro_line
        
        conversation_history[call_sid].append({"role": "assistant", "content": reply})
    else:
        # Add user message to history BEFORE calling GPT
        conversation_history[call_sid].append({"role": "user", "content": transcript})
        
        # Build messages array with proper ordering
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add tool instruction ONLY ONCE (not every turn)
        if turn > 0:  # Skip on very first turn
            tool_instruction = {
                "role": "system", 
                "content": "If you use the check_remaining_time tool, incorporate the time information naturally into your response. Don't ignore the tool result."
            }
            messages.append(tool_instruction)
        
        # Check for bad news and add escalation if needed
        lowered = transcript.lower()
        is_bad_news = any(x in lowered for x in [
            "bad news", "unfortunately", "delay", "delayed", "won't make it", "can't deliver",
            "got pushed", "rescheduled", "not coming", "issue with the supplier", "problem with your order"
        ])

        is_user_defensive = any(x in lowered for x in [
            "calm down", "relax", "it's not my fault", "what do you want me to do", "stop yelling", "chill out"
        ])
        contains_profanity = any(word in lowered for word in PROFANITY_LIST)

        if is_bad_news or contains_profanity:
            if contains_profanity:
                print("ðŸ¤¬ Profanity detected â€” AI will respond with matching anger.")
                escalation_prompt = (
                    "The user just cursed at you. Based on your personality, respond with appropriate anger. "
                    "You can curse back if it fits your character. Say things like 'Don't you dare talk to me like that!' "
                    "or 'Who the hell do you think you're talking to?' or match their energy. "
                    "If this is the 3rd time they've been rude, you can say something like "
                    "'You know what? I'm done with this conversation. *click*' but only if they've been "
                    "repeatedly abusive."
                )
            else:
                print("âš ï¸ Bad news detected â€” AI will respond angrily.")
                escalation_prompt = (
                    "The user just delivered bad news to the customer. Respond as the customer based on your personality, "
                    "but crank up the emotion. If it fits your persona, act furious â€” like you're raising your voice. "
                    "You might say things like 'Are you SERIOUS right now?!' or 'Unbelievable. This is NOT okay.' "
                    "Show that this ruined your day. If the user tries to calm you down, don't immediately cool off. "
                    "Push back again with more anger. Only start to de-escalate if they take responsibility and handle it well. "
                    "Stay human, not robotic."
                )
            
            # MOVE THIS INSIDE THE BLOCK
            if is_user_defensive:
                print("ðŸ˜¡ User snapped back â€” escalate the attitude.")
                escalation_prompt += (
                    " The user got defensive, so now you're even more upset. Push back harder. Say something like, "
                    "'Don't tell me to calm down â€” this is your screw-up.'"
                )
        
            messages.append({
                "role": "system",
                "content": escalation_prompt
            })
            
        # Add clean conversation history (no partials, no duplicates)
        messages += get_clean_conversation_history(call_sid)
        
        # Debug if needed
        if os.getenv("DEBUG_CONVERSATION", "false").lower() == "true":
            debug_conversation_state(call_sid)
            print(f"ðŸ“‹ Messages array length: {len(messages)}")
            for i, msg in enumerate(messages):
                if isinstance(msg, dict) and "role" in msg:
                    content_preview = msg.get('content', '')[:50] + '...' if msg.get('content', '') else 'No content'
                    print(f"   [{i}] {msg['role']}: {content_preview}")

        # Check if we're close to timeout before GPT call
        if time.time() - start_time > MAX_PROCESSING_TIME - 3:
            print("âš ï¸ Near timeout, using quick response")
            reply = "Let me think about that for a moment."
        else:
            # Get GPT response
            try:
                if USE_STREAMING:
                    reply = await streaming_gpt_response(messages, voice_id, call_sid)
                else:
                    reply = get_gpt_response_with_tools(messages, call_sid)
            except Exception as e:
                print(f"ðŸ’¥ GPT error: {e}")
                # Fallback response
                reply = "I'm having a bit of trouble understanding. Could you say that again?"
                
        # Clean up response
        reply = reply.replace("*", "").replace("_", "").replace("`", "").replace("#", "").replace("-", " ")
        
        # Add final response to conversation history ONLY ONCE
        conversation_history[call_sid].append({"role": "assistant", "content": reply})

    # Use mode from voice_lock if available (for consistency)
    if call_sid in voice_lock and "mode" in voice_lock[call_sid]:
        mode = voice_lock[call_sid]["mode"]
    
    print(f"ðŸ”£ Generating voice with ID: {voice_id}")
    
    # Log which persona/character is speaking
    if mode == "cold_call" or mode == "customer_convo":
        persona_info = personality_memory.get(call_sid, {})
        if isinstance(persona_info, dict):
            persona_name = persona_info.get("persona_name", "Unknown")
        else:
            persona_name = "Unknown"
        print(f"ðŸŽ­ Speaking as: {persona_name}")
    elif mode == "interview":
        interviewer = personality_memory.get(call_sid, {})
        if isinstance(interviewer, dict):
            print(f"ðŸŽ­ Speaking as: {interviewer.get('name', 'Unknown')} (Interviewer)")
    elif mode == "small_talk":
        print(f"ðŸŽ­ Speaking as: Casual Friend")
    
    print(f"ðŸ—£ï¸ Reply: {reply[:100]}...")
    
    # Generate TTS with timeout protection
    output_path = f"static/response_{call_sid}.mp3"
    
    # Check if we're close to timeout
    if time.time() - start_time > MAX_PROCESSING_TIME - 2:
        print("âš ï¸ Near timeout, using fallback audio")
        fallback_path = "static/fallback.mp3"
        if os.path.exists(fallback_path):
            os.system(f"cp {fallback_path} {output_path}")
        else:
            # Create a very quick TTS response
            try:
                quick_gen = elevenlabs_client.text_to_speech.convert(
                    voice_id=voice_id,
                    text="Just a moment.",
                    model_id="eleven_turbo_v2_5",
                    output_format="mp3_22050_32"
                )
                raw_audio = b""
                for chunk in quick_gen:
                    if chunk:
                        raw_audio += chunk
                with open(output_path, "wb") as f:
                    f.write(raw_audio)
            except:
                pass
    else:
        # Normal TTS generation
        if USE_STREAMING and SENTENCE_STREAMING and turn > 0 and os.path.exists(output_path):
            # Audio already generated by streaming_gpt_response
            print(f"âœ… Audio already generated via sentence streaming for {call_sid}")
        else:
            # Generate TTS (streaming or non-streaming)
            try:
                audio_gen = elevenlabs_client.text_to_speech.convert(
                    voice_id=voice_id,
                    text=reply,
                    model_id=MODELS["elevenlabs"]["voice_model"],
                    output_format=MODELS["elevenlabs"]["output_format"]
                )
                raw_audio = b""
                for chunk in audio_gen:
                    if chunk:
                        raw_audio += chunk
                
                with open(output_path, "wb") as f:
                    f.write(raw_audio)
                    f.flush()
                print(f"âœ… Audio saved to {output_path} ({len(raw_audio)} bytes)")
                    
            except Exception as e:
                print(f"ðŸ›‘ ElevenLabs generation error: {e}")
                if "429" in str(e):  # Too Many Requests
                    print("ðŸ” Retrying after brief pause due to rate limit...")
                    await asyncio.sleep(2)
                    try:
                        if USE_STREAMING:
                            raw_audio = await generate_tts_streaming(reply, voice_id)
                        else:
                            audio_gen = elevenlabs_client.text_to_speech.convert(
                                voice_id=voice_id,
                                text=reply,
                                model_id=MODELS["elevenlabs"]["voice_model"],
                                output_format=MODELS["elevenlabs"]["output_format"]
                            )
                            raw_audio = b""
                            for chunk in audio_gen:
                                if chunk:
                                    raw_audio += chunk
                            
                        with open(output_path, "wb") as f:
                            f.write(raw_audio)
                        print("âœ… Retry succeeded")
                    except Exception as e2:
                        print(f"âŒ Retry failed: {e2}")
                        fallback_path = "static/fallback.mp3"
                        if os.path.exists(fallback_path):
                            os.system(f"cp {fallback_path} {output_path}")
    
    # Always create ready flag after audio is saved
    with open(f"static/response_ready_{call_sid}.txt", "w") as f:
        f.write("ready")
    print(f"ðŸš© Ready flag created for {call_sid}")

    # Schedule cleanup
    cleanup_thread = threading.Thread(target=delayed_cleanup, args=(call_sid,))
    cleanup_thread.start()

    # Check if this is the final message before ending
    is_ending = False
    with state_lock:
        if active_sessions.get(call_sid) == "ENDING":
            is_ending = True
            print(f"ðŸ”š This is the final message before ending call {call_sid}")

    # Build response
    response = VoiceResponse()
    
    if is_ending:
        # Play the goodbye message and then hangup
        response.play(f"{request.url_root}static/response_{call_sid}.mp3")
        response.pause(length=1)
        response.hangup()
        
        # Send SMS after goodbye
        if call_sid in active_streams:
            from_number = active_streams[call_sid].get('from_number')
            if from_number:
                usage_data = read_user_usage(from_number)
                is_first_call = usage_data['total_calls'] <= 1
                print(f"ðŸ“¤ Sending SMS after AI goodbye")
                send_convoreps_sms_link(from_number, is_first_call=is_first_call)
    else:
        # Normal flow - continue conversation
        response.redirect(url_for("voice", _external=True))
    
    return str(response)
async def streaming_transcribe(audio_file_path: str) -> str:
    """Transcription with streaming control"""
    try:
        if USE_STREAMING:
            # Try streaming transcription
            with open(audio_file_path, "rb") as audio_file:
                try:
                    stream = await async_openai.audio.transcriptions.create(
                        model=MODELS["openai"]["streaming_transcribe"],
                        file=audio_file,
                        response_format="text",
                        stream=True, language='en'
                    )
                    
                    transcript = ""
                    async for event in stream:
                        if hasattr(event, 'delta') and hasattr(event.delta, 'text'):
                            transcript += event.delta.text
                        elif hasattr(event, 'text') and event.text:
                            transcript = event.text
                            
                    return transcript.strip()
                    
                except Exception as e:
                    print(f"âš ï¸ Streaming transcription failed: {e}")
                    # Fall through to non-streaming
        
        # Non-streaming (either USE_STREAMING=False or fallback)
        with open(audio_file_path, "rb") as f:
            result = sync_openai.audio.transcriptions.create(
                model=MODELS["openai"]["standard_transcribe"],
                file=f
            )
            return result.text.strip()
                
    except Exception as e:
        print(f"ðŸ’¥ Transcription error: {e}")
        raise

async def streaming_gpt_response(messages: list, voice_id: str, call_sid: str) -> str:
    """Stream GPT response and generate TTS concurrently with tool support"""
    try:
        model = MODELS["openai"]["streaming_gpt"] if USE_STREAMING else MODELS["openai"]["standard_gpt"]
        
        if USE_STREAMING and SENTENCE_STREAMING:
            # Create output file immediately
            output_path = f"static/response_{call_sid}.mp3"
            
            # Streaming with sentence detection
            stream = await async_openai.chat.completions.create(
                model=model,
                messages=messages,
                stream=True,
                temperature=0.7,
                tools=[get_time_check_tool()],
                tool_choice="auto"
            )
            
            full_response = ""
            sentence_buffer = ""
            sentence_count = 0
            first_audio_saved = False
            final_tool_calls = {}
            
            async for chunk in stream:
                # Handle tool calls - accumulate them properly
                if chunk.choices[0].delta.tool_calls:
                    for tool_call_delta in chunk.choices[0].delta.tool_calls:
                        index = tool_call_delta.index
                        
                        if index not in final_tool_calls:
                            final_tool_calls[index] = {
                                "id": tool_call_delta.id,
                                "type": "function",
                                "function": {
                                    "name": tool_call_delta.function.name if tool_call_delta.function else None,
                                    "arguments": ""
                                }
                            }
                        
                        if tool_call_delta.function and tool_call_delta.function.arguments:
                            final_tool_calls[index]["function"]["arguments"] += tool_call_delta.function.arguments
                
                # Process content
                if chunk.choices[0].delta.content:
                    text = chunk.choices[0].delta.content
                    sentence_buffer += text
                    full_response += text
                    
                    # Check for sentence completion
                    sentences = re.split(r'(?<=[.!?])\s+', sentence_buffer)
                    
                    # Process complete sentences immediately
                    for sentence in sentences[:-1]:
                        if sentence.strip():
                            sentence_count += 1
                            print(f"ðŸŽ¯ Processing sentence {sentence_count}: {sentence[:30]}...")
                            
                            # Generate TTS for this sentence
                            try:
                                audio_data = await generate_tts_streaming(sentence, voice_id)
                                
                                # Save first sentence immediately
                                if not first_audio_saved:
                                    with open(output_path, "wb") as f:
                                        f.write(audio_data)
                                    first_audio_saved = True
                                    print(f"âœ… First audio chunk saved - ready to play!")
                                else:
                                    # Append subsequent sentences
                                    with open(output_path, "ab") as f:
                                        f.write(audio_data)
                                        
                            except Exception as e:
                                print(f"âš ï¸ TTS error for sentence {sentence_count}: {e}")
                    
                    sentence_buffer = sentences[-1] if sentences else ""
            
            # Process final sentence from initial stream
            if sentence_buffer.strip() and not final_tool_calls:
                try:
                    audio_data = await generate_tts_streaming(sentence_buffer, voice_id)
                    if not first_audio_saved:
                        with open(output_path, "wb") as f:
                            f.write(audio_data)
                    else:
                        with open(output_path, "ab") as f:
                            f.write(audio_data)
                except Exception as e:
                    print(f"âš ï¸ TTS error for final sentence: {e}")
            
            # Handle tool calls if present
            if final_tool_calls:
                # Process the first tool call
                tool_call = final_tool_calls[0]
                if tool_call["function"]["name"] == "check_remaining_time":
                    print(f"ðŸ”§ Processing tool call in streaming mode")
                    tool_result = handle_tool_call(call_sid)
                    
                    # Check if time expired
                    if "TIME_EXPIRED" in tool_result:
                        print(f"â° Tool detected time expired - AI will say goodbye")
                        with state_lock:
                            active_sessions[call_sid] = "ENDING"
                    
                    # Build new messages array with tool call and result
                    tool_messages = messages.copy()
                    tool_messages.append({
                        "role": "assistant",
                        "content": full_response if full_response else None,
                        "tool_calls": [{
                            "id": tool_call["id"],
                            "type": "function",
                            "function": {
                                "name": "check_remaining_time",
                                "arguments": tool_call["function"]["arguments"]
                            }
                        }]
                    })
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": tool_result
                    })
                    
                    print(f"ðŸ“Š Getting final response after tool call with result: {tool_result}")
                    
                    # Get final response based on tool result
                    final_stream = await async_openai.chat.completions.create(
                        model=model,
                        messages=tool_messages,
                        stream=True,
                        temperature=0.7
                    )
                    
                    final_response = ""
                    sentence_buffer = ""
                    
                    # Process the final response that incorporates the tool result
                    async for chunk in final_stream:
                        if chunk.choices[0].delta.content:
                            text = chunk.choices[0].delta.content
                            sentence_buffer += text
                            final_response += text
                            
                            # Process complete sentences
                            sentences = re.split(r'(?<=[.!?])\s+', sentence_buffer)
                            for sentence in sentences[:-1]:
                                if sentence.strip():
                                    try:
                                        audio_data = await generate_tts_streaming(sentence, voice_id)
                                        # Append to existing audio file
                                        with open(output_path, "ab") as f:
                                            f.write(audio_data)
                                        print(f"ðŸ”Š Added tool response sentence to audio: {sentence[:50]}...")
                                    except Exception as e:
                                        print(f"âš ï¸ TTS error for tool response sentence: {e}")
                            
                            sentence_buffer = sentences[-1] if sentences else ""
                    
                    # Process final sentence buffer
                    if sentence_buffer.strip():
                        try:
                            audio_data = await generate_tts_streaming(sentence_buffer, voice_id)
                            with open(output_path, "ab") as f:
                                f.write(audio_data)
                            print(f"ðŸ”Š Added final tool response sentence to audio")
                        except Exception as e:
                            print(f"âš ï¸ TTS error for final tool response sentence: {e}")
                    
                    print(f"ðŸŽ™ï¸ AI final response with time info: {final_response.strip()[:100]}...")
                    return final_response.strip()
            
            # If no tool call, return the regular response
            return full_response.strip()
            
        else:
            # Non-streaming with tool support
            completion = await async_openai.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                tools=[get_time_check_tool()],
                tool_choice="auto"
            )
            
            response_message = completion.choices[0].message
            
            if response_message.tool_calls:
                tool_call = response_message.tool_calls[0]
                if tool_call.function.name == "check_remaining_time":
                    tool_result = handle_tool_call(call_sid)
                    
                    # Check if time expired
                    if "TIME_EXPIRED" in tool_result:
                        print(f"â° Tool detected time expired - AI will say goodbye")
                        with state_lock:
                            active_sessions[call_sid] = "ENDING"
                    
                    # Build new messages with tool call and result
                    tool_messages = messages.copy()
                    tool_messages.append({
                        "role": "assistant",
                        "content": response_message.content,
                        "tool_calls": [{
                            "id": tool_call.id,
                            "type": "function", 
                            "function": {
                                "name": "check_remaining_time",
                                "arguments": tool_call.function.arguments
                            }
                        }]
                    })
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })
                    
                    # Get final response based on tool result
                    print(f"ðŸ¤– Getting AI response based on tool result: {tool_result}")
                    final_completion = await async_openai.chat.completions.create(
                        model=model,
                        messages=tool_messages,
                        temperature=0.7
                    )
                    final_reply = final_completion.choices[0].message.content.strip()
                    print(f"ðŸŽ™ï¸ AI final response with time info: {final_reply[:100]}...")
                    
                    return final_reply
            
            # No tool call - return regular response
            return response_message.content.strip()
            
    except Exception as e:
        print(f"ðŸ’¥ GPT streaming error: {e}")
        import traceback
        traceback.print_exc()
        # Fallback to non-streaming with proper tool handling
        try:
            completion = sync_openai.chat.completions.create(
                model=MODELS["openai"]["standard_gpt"],
                messages=messages,
                tools=[get_time_check_tool()],
                tool_choice="auto"
            )
            
            response_message = completion.choices[0].message
            
            # Handle tool calls in fallback
            if response_message.tool_calls:
                tool_call = response_message.tool_calls[0]
                if tool_call.function.name == "check_remaining_time":
                    tool_result = handle_tool_call(call_sid)
                    
                    # Check if time expired
                    if "TIME_EXPIRED" in tool_result:
                        print(f"â° Tool detected time expired in fallback - AI will say goodbye")
                        with state_lock:
                            active_sessions[call_sid] = "ENDING"
                    
                    # Build messages properly
                    tool_messages = messages.copy()
                    tool_messages.append({
                        "role": "assistant",
                        "content": response_message.content,
                        "tool_calls": response_message.tool_calls
                    })
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result
                    })
                    
                    # Get final response
                    final_completion = sync_openai.chat.completions.create(
                        model=MODELS["openai"]["standard_gpt"],
                        messages=tool_messages,
                        temperature=0.7
                    )
                    final_reply = final_completion.choices[0].message.content.strip()
                    print(f"ðŸŽ™ï¸ Fallback AI response with time info: {final_reply[:100]}...")
                    return final_reply
            
            return response_message.content.strip()
            
        except Exception as e2:
            print(f"ðŸ’¥ Fallback also failed: {e2}")
            return "I'm having trouble processing that. Could you please repeat?"

async def generate_tts_streaming(text: str, voice_id: str) -> bytes:
    """Generate TTS using streaming ElevenLabs API with retry logic"""
    max_retries = 3
    retry_delay = 1.0
    
    for attempt in range(max_retries):
        try:
            if USE_STREAMING:
                # Use streaming TTS
                response = elevenlabs_client.text_to_speech.stream(
                    voice_id=voice_id,
                    text=text,
                    model_id=MODELS["elevenlabs"]["voice_model"],
                    output_format=MODELS["elevenlabs"]["output_format"],
                    voice_settings=VoiceSettings(
                        stability=0.4,
                        similarity_boost=0.75
                    )
                )
                
                # Collect audio chunks
                audio_data = io.BytesIO()
                chunk_count = 0
                for chunk in response:
                    if chunk:
                        audio_data.write(chunk)
                        chunk_count += 1
                
                if chunk_count == 0:
                    raise Exception("No audio chunks received")
                        
                audio_data.seek(0)
                return audio_data.read()
                
            else:
                # Fallback to non-streaming
                audio_gen = elevenlabs_client.text_to_speech.convert(
                    voice_id=voice_id,
                    text=text,
                    model_id=MODELS["elevenlabs"]["voice_model"],
                    output_format=MODELS["elevenlabs"]["output_format"]
                )
                
                audio_data = b""
                for chunk in audio_gen:
                    if chunk:
                        audio_data += chunk
                        
                return audio_data
                
        except Exception as e:
            print(f"ðŸ’¥ TTS attempt {attempt + 1} failed: {e}")
            if "10054" in str(e) or "connection" in str(e).lower():
                # Connection error - wait and retry
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                    continue
            
            # For last attempt or non-connection errors, try fallback
            if attempt == max_retries - 1:
                print("ðŸ”„ Falling back to non-streaming TTS...")
                try:
                    audio_gen = elevenlabs_client.text_to_speech.convert(
                        voice_id=voice_id,
                        text=text,
                        model_id=MODELS["elevenlabs"]["voice_model"],
                        output_format=MODELS["elevenlabs"]["output_format"]
                    )
                    
                    audio_data = b""
                    for chunk in audio_gen:
                        if chunk:
                            audio_data += chunk
                            
                    return audio_data
                except Exception as e2:
                    print(f"âŒ TTS fallback also failed: {e2}")
                    raise
    
    raise Exception("All TTS attempts failed")



if __name__ == "__main__":
    # Ensure static directory and files exist
    ensure_static_files()
    
    # Initialize CSV for minute tracking
    init_csv()
    print(f"ðŸ“Š CSV tracking enabled at: {USAGE_CSV_PATH}")
    
    print("\nðŸš€ ConvoReps Streaming Edition")
    print(f"   USE_STREAMING: {USE_STREAMING}")
    print(f"   SENTENCE_STREAMING: {SENTENCE_STREAMING}")
    print(f"   STREAMING_TIMEOUT: {STREAMING_TIMEOUT}s")
    print(f"\nðŸ“¦ Model Configuration:")
    print(f"   OpenAI Streaming: {MODELS['openai']['streaming_gpt']}")
    print(f"   OpenAI Standard: {MODELS['openai']['standard_gpt']}")
    print(f"   Transcription: {MODELS['openai']['streaming_transcribe']} / {MODELS['openai']['standard_transcribe']}")
    print(f"   ElevenLabs: {MODELS['elevenlabs']['voice_model']}")
    print(f"\nðŸŽ­ Voice Consistency:")
    print(f"   Once a mode is selected, the same voice is used throughout the call")
    print(f"   Cold Call: One of 14 personas")
    print(f"   Interview: One of 3 interviewers (Rachel, Clyde, Stephen)")
    print(f"   Small Talk: Casual friend voice")
    print("\n")
    
    print(f"ðŸ Application started on port 5050")
    print(f"ðŸ“Š Free minutes per user: {FREE_CALL_MINUTES}")
    print(f"â±ï¸ Minimum call duration: {MIN_CALL_DURATION} minutes")
    print(f"\nðŸ“ž IMPORTANT: Configure your Twilio phone number with:")
    print(f"   Voice Configuration:")
    print(f"   - A CALL COMES IN â†’ Webhook: https://your-domain.com/voice (HTTP POST)")
    print(f"   - CALL STATUS CHANGES â†’ https://your-domain.com/call_status (HTTP POST)")
    print(f"   - PRIMARY HANDLER FAILS â†’ Leave empty")
    print(f"\n   This ensures proper call tracking and cleanup!")
    
    app.run(host="0.0.0.0", port=5050)
